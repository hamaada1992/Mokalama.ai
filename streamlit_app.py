import streamlit as st
import os
import tempfile
import pandas as pd
import json
from faster_whisper import WhisperModel
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import torch
import gc
import re

st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù…", layout="wide")
st.title("ğŸ§ ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ")

@st.cache_resource
def load_whisper_model():
    return WhisperModel("base", device="cpu", compute_type="float32")

@st.cache_resource
def load_sentiment_model():
    model_name = "CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    return pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

def clear_memory():
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()

def clean_text(text):
    return re.sub(r"[^\u0600-\u06FF\s]", "", text).strip()

corrections = {
    "Ø§Ù„ÙØªÙˆØ±": "Ø§Ù„ÙØ§ØªÙˆØ±Ø©", "Ø²ÙŠØ§Ø¯": "Ø²ÙŠØ§Ø¯Ø©", "Ø§Ù„Ù„ÙŠØ²ÙˆÙ…": "Ø§Ù„Ù„Ø²ÙˆÙ…", "Ø§Ù„Ù…ØµØ§Ø¯Ø©": "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©",
    "Ø¨Ø¯ÙŠ Ø¨Ø·Ù„": "Ø¨Ø¯ÙŠ Ø£Ø¨Ø¯Ù„", "Ù…Ø¹ Ø¨ÙˆÙ„": "Ù…Ø¹ Ø¨ÙˆÙ„ÙŠØµØ©", "ØªØ§Ø²ÙŠ": "ØªØ§Ø²Ø©", "Ø§Ø¯Ø§Ù… Ø§Ù„ÙÙ†ÙŠ": "Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙÙ†ÙŠ",
    "Ø£Ø¨Ø±ÙŠØ¨Ø§": "Ø£Ø¨ØºÙŠ", "Ø¯ÙŠÙ„": "Ø¨Ø¯ÙŠÙ„", "Ø§Ù„Ø¹Ù„Ø§Ù†": "Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†", "Ø´Ù†Ù„": "Ø´Ù†Ùˆ", "ÙÙŠÙ†": "Ø£ÙŠÙ†",
    "Ø§Ù„Ø¶ÙØ¹": "Ø§Ù„Ø¯ÙØ¹", "Ø¨ÙŠÙ‚Ø§Ù„": "Ø¨Ø§ÙŠ Ø¨Ø§Ù„", "Ø§Ù„Ù…ÙˆØ§Ø¶Ù": "Ø§Ù„Ù…ÙˆØ¸Ù", "Ù…Ù‡Ø¯Ø¨": "Ù…Ù‡Ø°Ø¨"
}

def manual_correction(text):
    for wrong, right in corrections.items():
        text = text.replace(wrong, right)
    return text

def transcribe_audio(path, model):
    segments, _ = model.transcribe(path)
    return " ".join([seg.text for seg in segments])

whisper_model = load_whisper_model()
sentiment_pipeline = load_sentiment_model()

uploaded_files = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ©", type=["wav", "mp3", "flac"], accept_multiple_files=True)

if uploaded_files:
    results = []
    with st.spinner("â³ Ø¬Ø§Ø±Ù Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª..."):
        for uploaded_file in uploaded_files:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_path = tmp_file.name

            call_id = os.path.splitext(uploaded_file.name)[0]
            raw = transcribe_audio(tmp_path, whisper_model)
            clean = clean_text(raw)
            corrected = manual_correction(clean)

            try:
                sentiment = sentiment_pipeline(corrected)[0] if len(corrected.split()) > 2 else {"label": "neutral", "score": 0.5}
            except:
                sentiment = {"label": "neutral", "score": 0.5}

            results.append({
                "call_id": call_id,
                "text_raw": raw,
                "text_clean": clean,
                "text_corrected": corrected,
                "sentiment_label": sentiment["label"],
                "sentiment_score": round(sentiment["score"], 2)
            })

            os.unlink(tmp_path)

    if results:
        df = pd.DataFrame(results)
        st.dataframe(df)
        st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ JSON", json.dumps(results, ensure_ascii=False, indent=2), file_name="call_results.json")
        st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ CSV", df.to_csv(index=False).encode("utf-8-sig"), file_name="call_results.csv")
        clear_memory()
    else:
        st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø¥Ù†ØªØ§Ø¬ Ù†ØªØ§Ø¦Ø¬")
