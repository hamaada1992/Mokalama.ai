import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["STREAMLIT_SERVER_FILE_WATCHER_TYPE"] = "poll")

import streamlit as st
import tempfile
import pandas as pd
import plotly.express as px
import json
import torch
import re
import time
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from faster_whisper import WhisperModel
import arabic_reshaper
from bidi.algorithm import get_display

st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù…", layout="wide")
st.title("ðŸŽ§ ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±")

# Initialize Arabic text processor
def format_arabic(text):
    reshaped_text = arabic_reshaper.reshape(text)
    return get_display(reshaped_text)

# Model selection
st.sidebar.header(format_arabic("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"))
model_size = st.sidebar.radio(
    format_arabic("Ø­Ø¬Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµÙˆØª"), 
    ["tiny", "base", "small"], 
    index=1,
    help=format_arabic("Ø§Ø®ØªØ± tiny Ù„ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø±Ø¹ Ø£Ùˆ small/base Ù„Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰")
)

@st.cache_resource(show_spinner=False)
def load_whisper_model(size):
    st.info(format_arabic(f"â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµÙˆØª ({size})..."))
    return WhisperModel(
        size, 
        device="cpu", 
        compute_type="int8",
        download_root="./whisper_models"
    )

whisper_model = load_whisper_model(model_size)

@st.cache_resource(show_spinner=False)
def load_sentiment_model():
    model_name = "CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment"
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        return pipeline(
            "text-classification", 
            model=model, 
            tokenizer=tokenizer,
            truncation=True,
            max_length=256,
            top_k=1
        )
    except Exception as e:
        st.error(format_arabic(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {str(e)}"))
        st.stop()

sentiment_pipeline = load_sentiment_model()

# Enhanced corrections dictionary with regex patterns
corrections = [
    (r"\bØ§Ù„ÙØªÙˆØ±\b", "Ø§Ù„ÙØ§ØªÙˆØ±Ø©"),
    (r"\bØ²ÙŠØ§Ø¯\b", "Ø²ÙŠØ§Ø¯Ø©"),
    (r"\bØ§Ù„Ù„ÙŠØ²ÙˆÙ…\b", "Ø§Ù„Ù„Ø²ÙˆÙ…"),
    (r"\bØ§Ù„Ù…ØµØ§Ø¯Ø©\b", "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©"),
    (r"\bØ¨Ø¯ÙŠ Ø¨Ø·Ù„\b", "Ø¨Ø¯ÙŠ Ø£Ø¨Ø¯Ù„"),
    (r"\bÙ…Ø¹ Ø¨ÙˆÙ„\b", "Ù…Ø¹ Ø¨ÙˆÙ„ÙŠØµØ©"),
    (r"\bØªØ§Ø²ÙŠ\b", "ØªØ§Ø²Ø©"),
    (r"\bØ¥?Ø¯Ø§Ù… Ø§Ù„ÙÙ†ÙŠ\b", "Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙÙ†ÙŠ"),
    (r"\bØ¨Ø§Ù„Ø¯ÙŠ\b", "Ø¨Ø¯ÙŠ"),
    (r"\bØ§Ù„Ø¬ÙˆØ¯ÙŠ\b", "Ø§Ù„Ø¬ÙˆØ¯Ø©"),
    (r"\bØ§Ù„ØªÙˆÙ‚Ø¹Ø§ØªÙŠ\b", "ØªÙˆÙ‚Ø¹Ø§ØªÙŠ"),
    (r"\bÙ…Ø¹ Ø·ÙˆØ¨\b", "Ù…Ø¹Ø·ÙˆØ¨"),
    (r"\bØ£Ø¨Ø±ÙŠØ¨Ø§ Ø¯ÙŠÙ„\b", "Ø£Ø¨ØºÙŠ Ø¨Ø¯ÙŠÙ„"),
    (r"\bØ´Ù†Ù„\b", "Ø´Ù†Ùˆ"),
    (r"\bØ§Ù„Ø¹Ù„Ø§Ù†\b", "Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†"),
    (r"\bØ§Ù„Ù…ÙˆØ§Ø¶Ù\b", "Ø§Ù„Ù…ÙˆØ¸Ù"),
    (r"\bÙ…Ù‡Ø¯Ø¨\b", "Ù…Ù‡Ø°Ø¨"),
    (r"\bØ§Ù„Ø¶ÙØ¹\b", "Ø§Ù„Ø¯ÙØ¹"),
    (r"\bØ¨ÙŠÙ‚Ø§Ù„\b", "Ø¨Ø§ÙŠØ¨Ø§Ù„"),
    (r"\bØ§Ù„Ù„Ø¹Ø¸Ù…\b", "Ø§Ù„Ù„Ø§Ø²Ù…"),
    (r"\bÙŠÙ†ÙØ¹Ø§Ø¯\b", "ÙŠÙ†ÙØ¹ Ø§Ø¹Ø¯Ù„"),
    (r"\bØ£Ø¨Ù„ Ù…ÙŠØª Ø´Ù‡Ø±\b", "Ù‚Ø¨Ù„ Ù…Ø§ ÙŠØªØ´Ø­Ù†"),
    (r"\bÙ„Ø®Ø¨Ø± Ù‡Ùƒ Ù…Ø§ Ø¨Ø³ÙŠØ±\b", "Ø§Ù„Ø®Ø¨Ø± Ù‡ÙŠÙƒ Ù…Ø§ Ø¨ØµÙŠØ±"),
    (r"\bÙŠØ¹ØªÙŠÙƒÙ…\b", "ÙŠØ¹Ø·ÙŠÙƒÙ…"),
    (r"\bØ¹Ù† Ø¬Ø¯ Ø§Ù„ØªØ¹Ø§Ù…Ù„\b", "Ø¹Ù†Ø¬Ø¯ Ø§Ù„ØªØ¹Ø§Ù…Ù„"),
    (r"\bÙˆØ´Ø­Ù† ÙˆØµÙ„Øª\b", "ÙˆØ§Ù„Ø´Ø­Ù†Ø© ÙˆØµÙ„Øª"),
    (r"\bÙ…Ø§ ØªØ§Ø¨ÙƒÙˆÙ† Ø§Ù„ØªÙˆØµÙŠÙ„\b", "Ù…ØªÙ‰ Ø¨ÙŠÙƒÙˆÙ† Ø§Ù„ØªÙˆØµÙŠÙ„"),
    (r"\bØªØ£Ø®Ø± ÙˆØ§Ø¬Ø¯\b", "ØªØ£Ø®Ø± ÙƒØ«ÙŠØ±"),
    (r"\bØ¹Ø¶Ø±ÙˆØ±ÙŠ\b", "Ø¶Ø±ÙˆØ±ÙŠ"),
    (r"\bØªØ¨ÙƒÙˆÙ†\b", "Ø¨ÙŠÙƒÙˆÙ†"),
    (r"\bØ¨Ø¯ÙŠ Ø£Ù„ØºÙŠ Ø·Ù„Ø¨ Ø±Ø£Ù… ÙˆØ§Ø­Ø¯ Ù„Ø§ØªÙŠ Ø®Ù…Ø³ Ø³Ø¨Ø¹Ø© ØªØ³Ø¹Ø©\b", "Ø¨Ø¯ÙŠ Ø£Ù„ØºÙŠ Ø·Ù„Ø¨ Ø±Ù‚Ù… 13579"),
    (r"\bØ§Ù„Ù…Ù†ØªÙ‚Ø¬\b", "Ø§Ù„Ù…Ù†ØªØ¬"),
    (r"\bØ£ÙÙŠÙ†\b", "Ø£ÙŠÙ†"),
    (r"\bØ§Ù„Ù„Ø³Ø©\b", "Ù„Ø­Ø¯ Ø§Ù„Ø¢Ù†"),
    (r"\bÙ…Ø­Ø¯\b", "Ù…Ø§ Ø­Ø¯"),
    (r"\bÙ‡Ø§ ÙƒØ±Ø±Ù‡Ø§\b", "Ø±Ø­ Ø£ÙƒØ±Ø±Ù‡Ø§"),
    (r"\bØ£Ø¨Ø¯Ù„\b", "Ø£Ø¨Ø¯Ù„"),
    (r"\bØ±Ø£Ù…\b", "Ø±Ù‚Ù…"),
    (r"\bØºÙŠØ·\b", "Ø§Ù„ØºÙŠØª"),
    (r"\bØ³Ø¹Ù‰\b", "ØªØ³Ø¹Ø©"),
    (r"\bÙ„Ø§ØªÙŠ\b", "ÙˆØ§Ø­Ø¯"),
    (r"\bØ®Ù…Ø³ Ø³Ø¨Ø¹Ø§Øª\b", "Ø®Ù…Ø³Ø© Ø³Ø¨Ø¹Ø©"),
    (r"\bØ¨Ø¯Ø£Ù„\b", "Ø¨Ø¯ÙŠ Ø£Ù„ØºÙŠ"),
    (r"\bØ¹Ø²Ø± Ø§Ù„Ø¬Ø¹Ùˆ\b", "Ø¹Ù„Ù‰ Ø§Ù„Ø¬ÙˆØ¯Ø©"),
    (r"\bØªØ£Ø¨Ù„\b", "Ø·Ø±ÙŠÙ‚Ø©"),
    (r"\bØ§Ø¶Ø§ÙØ¹\b", "Ø§Ù„Ø¯ÙØ¹"),
    (r"\bÙ…Ù†ØªÙƒ\b", "Ø§Ù„Ù…Ù†ØªØ¬"),
    (r"\bÙ…Ø£Ø¨ÙˆÙ„\b", "Ù…Ù‚Ø¨ÙˆÙ„"),
]

# Common Arabic technical terms
tech_terms = {
    "ÙØ§ØªÙˆØ±Ø©": "ÙØ§ØªÙˆØ±Ø©",
    "Ø¯ÙØ¹": "Ø¯ÙØ¹",
    "Ù…Ù†ØªØ¬": "Ù…Ù†ØªØ¬",
    "ØªÙˆØµÙŠÙ„": "ØªÙˆØµÙŠÙ„",
    "Ø´Ø­Ù†": "Ø´Ø­Ù†",
    "Ø®Ø¯Ù…Ø©": "Ø®Ø¯Ù…Ø©",
    "Ø¯Ø¹Ù…": "Ø¯Ø¹Ù…",
    "ÙÙ†ÙŠ": "ÙÙ†ÙŠ",
    "Ø¬ÙˆØ¯Ø©": "Ø¬ÙˆØ¯Ø©",
    "Ø§Ø³ØªØ¨Ø¯Ø§Ù„": "Ø§Ø³ØªØ¨Ø¯Ø§Ù„",
    "Ø¥Ø±Ø¬Ø§Ø¹": "Ø¥Ø±Ø¬Ø§Ø¹",
    "Ø¶Ù…Ø§Ù†": "Ø¶Ù…Ø§Ù†",
    "Ø¨Ø·Ø§Ù‚Ø©": "Ø¨Ø·Ø§Ù‚Ø©",
    "Ø¯ÙØ¹": "Ø¯ÙØ¹",
    "ØªØ£Ø®ÙŠØ±": "ØªØ£Ø®ÙŠØ±",
    "Ø·Ù„Ø¨": "Ø·Ù„Ø¨",
    "Ø±Ù‚Ù…": "Ø±Ù‚Ù…",
    "Ø¹Ù…ÙŠÙ„": "Ø¹Ù…ÙŠÙ„",
    "Ù…Ø´ÙƒÙ„Ø©": "Ù…Ø´ÙƒÙ„Ø©",
    "Ø­Ù„": "Ø­Ù„",
    "ØªØ³Ø±ÙŠØ¹": "ØªØ³Ø±ÙŠØ¹",
    "Ø§Ø³ØªÙØ³Ø§Ø±": "Ø§Ø³ØªÙØ³Ø§Ø±"
}

def clean_text(text):
    # Remove non-Arabic characters except spaces
    text = re.sub(r"[^\u0600-\u06FF\s]", "", text)
    # Remove extra spaces
    return re.sub(r"\s+", " ", text).strip()

def manual_correction(text):
    # First pass: fix common mistakes with regex
    for pattern, replacement in corrections:
        text = re.sub(pattern, replacement, text)
    
    # Second pass: ensure technical terms are correct
    for term, correct in tech_terms.items():
        if term in text:
            text = text.replace(term, correct)
    
    return text

def transcribe_audio(path):
    try:
        segments, info = whisper_model.transcribe(
            path, 
            beam_size=5,
            vad_filter=True,
            language="ar",
            initial_prompt="ØªØ­Ø¯Ø« Ø¹Ù† Ø§Ù„ÙÙˆØ§ØªÙŠØ± ÙˆØ§Ù„Ø¯ÙØ¹ ÙˆØ§Ù„Ù…Ù†ØªØ¬Ø§Øª ÙˆØ§Ù„ØªÙˆØµÙŠÙ„ ÙˆØ§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ ÙˆØ§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ©",
            word_timestamps=False
        )
        
        # Collect segments with confidence scores
        transcriptions = []
        for segment in segments:
            if segment.text.strip():
                transcriptions.append({
                    "text": segment.text,
                    "confidence": segment.avg_logprob
                })
        
        # Combine high-confidence segments first
        high_conf = [t["text"] for t in transcriptions if t["confidence"] > -0.5]
        low_conf = [t["text"] for t in transcriptions if t["confidence"] <= -0.5]
        
        return " ".join(high_conf + low_conf)[:4000]  # Limit to 4000 characters
    except Exception as e:
        st.error(format_arabic(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ: {str(e)}"))
        return ""

# File upload section
uploaded_files = st.file_uploader(
    format_arabic("ðŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ© (WAV, MP3, FLAC)"), 
    type=["wav", "mp3", "flac"], 
    accept_multiple_files=True
)

if uploaded_files:
    st.info(format_arabic(f"ðŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ {len(uploaded_files)} Ù…ÙƒØ§Ù„Ù…Ø©..."))
    start_time = time.time()
    results = []
    progress_bar = st.progress(0)
    status_text = st.empty()

    for i, uploaded_file in enumerate(uploaded_files):
        # Update progress
        progress_percent = int((i + 1) / len(uploaded_files) * 100)
        progress_bar.progress(progress_percent)
        status_text.text(format_arabic(f"ðŸ“ž Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø© {i+1}/{len(uploaded_files)}: {uploaded_file.name}"))
        
        try:
            # Create temp file
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_path = tmp_file.name
            
            call_id = os.path.splitext(uploaded_file.name)[0]
            
            # Transcription
            raw_text = transcribe_audio(tmp_path)
            
            # Skip processing if transcription failed
            if not raw_text.strip():
                results.append({
                    "call_id": call_id,
                    "error": "ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ",
                    "text_raw": "",
                    "text_clean": "",
                    "text_corrected": "",
                    "sentiment_label": "error",
                    "sentiment_score": 0.0,
                    "rank": "Error"
                })
                continue
            
            # Text processing
            clean_text = clean_text(raw_text)
            corrected_text = manual_correction(clean_text)
            
            # Sentiment analysis (skip if empty)
            if not corrected_text.strip():
                sentiment = {"label": "neutral", "score": 0.0}
                st.warning(format_arabic(f"Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø© {call_id}: Ø§Ù„Ù†Øµ ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ"))
            else:
                # Truncate to 256 tokens for model input
                sentiment_result = sentiment_pipeline(corrected_text[:1000])
                sentiment = sentiment_result[0] if sentiment_result else {"label": "neutral", "score": 0.0}
            
            # Determine rank
            label = sentiment["label"]
            score = round(sentiment["score"], 2)
            
            # Enhanced ranking system
            if label == "negative":
                if score > 0.85:
                    rank = format_arabic("Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹")
                elif score > 0.7:
                    rank = format_arabic("Ø¹Ø§Ù„ÙŠØ©")
                else:
                    rank = format_arabic("Ù…ØªÙˆØ³Ø·Ø©")
            elif label == "positive":
                rank = format_arabic("Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©")
            else:
                rank = format_arabic("Ù…Ø­Ø§ÙŠØ¯Ø©")

            results.append({
                "call_id": call_id,
                "text_raw": raw_text,
                "text_clean": clean_text,
                "text_corrected": corrected_text,
                "sentiment_label": label,
                "sentiment_score": score,
                "rank": rank
            })
            
        except Exception as e:
            st.error(format_arabic(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø© {uploaded_file.name}: {str(e)}"))
            results.append({
                "call_id": uploaded_file.name,
                "error": str(e),
                "text_raw": "",
                "text_clean": "",
                "text_corrected": "",
                "sentiment_label": "error",
                "sentiment_score": 0.0,
                "rank": "Error"
            })
        finally:
            # Clean up temporary file
            if 'tmp_path' in locals():
                try:
                    os.unlink(tmp_path)
                except:
                    pass

    # Clear progress indicators
    progress_bar.empty()
    status_text.empty()
    
    # Show performance metrics
    end_time = time.time()
    total_time = end_time - start_time
    avg_time = total_time / len(uploaded_files) if uploaded_files else 0
    st.success(format_arabic(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„! Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {total_time:.1f} Ø«Ø§Ù†ÙŠØ© ({avg_time:.1f} Ø«Ø§Ù†ÙŠØ©/Ù…ÙƒØ§Ù„Ù…Ø©)"))

    if results:
        df = pd.DataFrame(results)
        
        # Display results with tabs
        tab1, tab2, tab3 = st.tabs(["Ø§Ù„Ù†ØªØ§Ø¦Ø¬", "Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©", "ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"])
        
        with tab1:
            st.subheader(format_arabic("ðŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"))
            st.dataframe(df[["call_id", "text_corrected", "sentiment_label", "sentiment_score", "rank"]], 
                         use_container_width=True, height=400)
            
            # Detailed view
            st.subheader(format_arabic("ðŸ” Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„Ø©"))
            for idx, row in df.iterrows():
                with st.expander(format_arabic(f"Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø©: {row['call_id']} (Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {row['sentiment_label']})")):
                    st.caption(format_arabic("Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:"))
                    st.write(format_arabic(row['text_raw']))
                    st.caption(format_arabic("Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ­Ø­:"))
                    st.write(format_arabic(row['text_corrected']))
                    st.caption(format_arabic(f"ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {row['sentiment_label']} (Ø«Ù‚Ø©: {row['sentiment_score']:.2f})"))
                    st.caption(format_arabic(f"Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: {row['rank']}"))
        
        with tab2:
            st.subheader(format_arabic("ðŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ØµØ±ÙŠ"))
            
            col1, col2 = st.columns(2)
            with col1:
                fig1 = px.pie(df, names="sentiment_label", title=format_arabic("ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"),
                              color_discrete_map={'positive': 'green', 'negative': 'red', 'neutral': 'blue'})
                st.plotly_chart(fig1, use_container_width=True)
                
                fig3 = px.histogram(df, x="sentiment_score", nbins=20, 
                                   title=format_arabic("ØªÙˆØ²ÙŠØ¹ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"),
                                   color="sentiment_label")
                st.plotly_chart(fig3, use_container_width=True)
                
            with col2:
                fig2 = px.bar(df, x="rank", color="rank", 
                             title=format_arabic("ØªØµÙ†ÙŠÙ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª"),
                             category_orders={"rank": [format_arabic("Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹"), 
                                                     format_arabic("Ø¹Ø§Ù„ÙŠØ©"), 
                                                     format_arabic("Ù…ØªÙˆØ³Ø·Ø©"), 
                                                     format_arabic("Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©"), 
                                                     format_arabic("Ù…Ø­Ø§ÙŠØ¯Ø©"), 
                                                     "Error"]})
                st.plotly_chart(fig2, use_container_width=True)
                
                fig4 = px.scatter(df, x="sentiment_score", y="rank", color="sentiment_label",
                                title=format_arabic("Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ§Ù„Ø£Ù‡Ù…ÙŠØ©"))
                st.plotly_chart(fig4, use_container_width=True)
        
        with tab3:
            st.subheader(format_arabic("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"))
            st.caption(format_arabic("ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒØ§Ù…Ù„Ø© Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON Ø£Ùˆ CSV"))
            
            col1, col2 = st.columns(2)
            with col1:
                st.download_button(
                    format_arabic("ðŸ“¥ ØªØ­Ù…ÙŠÙ„ JSON"), 
                    json.dumps(results, ensure_ascii=False, indent=2), 
                    file_name="call_results.json", 
                    mime="application/json"
                )
            with col2:
                st.download_button(
                    format_arabic("ðŸ“¥ ØªØ­Ù…ÙŠÙ„ CSV"), 
                    df.to_csv(index=False).encode("utf-8-sig"), 
                    file_name="call_results.csv", 
                    mime="text/csv"
                )
            
            # Show sample JSON
            st.caption(format_arabic("Ù…Ø¹Ø§ÙŠÙ†Ø© JSON:"))
            st.json(results[0] if len(results) > 0 else {})
