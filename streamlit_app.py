import streamlit as st
import os
import tempfile
import pandas as pd
import plotly.express as px
import json
from faster_whisper import WhisperModel
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import torch
import gc

# Ø¥ØµÙ„Ø§Ø­ Ù…Ø´ÙƒÙ„Ø© torch.classes
try:
    if hasattr(torch.classes, '__path__'):
        pass
except RuntimeError as e:
    st.warning(f"âš ï¸ ØªÙ… ØªØ¬Ø§ÙˆØ² Ù…Ø´ÙƒÙ„Ø© torch.classes: {str(e)}")

st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù…", layout="wide")
st.title("ğŸ§ ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©")

@st.cache_resource
def load_whisper_model():
    try:
        model = WhisperModel("tiny", device="cpu", compute_type="float32")
        st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper Ø¨Ù†Ø¬Ø§Ø­")
        return model
    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper: {str(e)}")
        return None

whisper_model = load_whisper_model()

@st.cache_resource
def load_sentiment_model():
    try:
        model_name = "CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        sentiment_pipeline = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
        st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¨Ù†Ø¬Ø§Ø­")
        return sentiment_pipeline
    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {str(e)}")
        return None

sentiment_pipeline = load_sentiment_model()

# Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©
def clear_memory():
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()
    # ØªÙ…Øª Ø¥Ø²Ø§Ù„Ø© Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ legacy_caching.clear_cache() Ù„Ø£Ù†Ù‡ Ù„Ù… ÙŠØ¹Ø¯ Ù…Ø¯Ø¹ÙˆÙ…Ø§Ù‹

corrections = {
    "Ø§Ù„ÙØªÙˆØ±": "Ø§Ù„ÙØ§ØªÙˆØ±Ø©", "Ø²ÙŠØ§Ø¯": "Ø²ÙŠØ§Ø¯Ø©", "Ø§Ù„Ù„ÙŠØ²ÙˆÙ…": "Ø§Ù„Ù„Ø²ÙˆÙ…", "Ø§Ù„Ù…ØµØ§Ø¯Ø©": "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©",
    "Ø¨Ø¯ÙŠ Ø¨Ø·Ù„": "Ø¨Ø¯ÙŠ Ø£Ø¨Ø¯Ù„", "Ù…Ø¹ Ø¨ÙˆÙ„": "Ù…Ø¹ Ø¨ÙˆÙ„ÙŠØµØ©", "ØªØ§Ø²ÙŠ": "ØªØ§Ø²Ø©", "Ø§Ø¯Ø§Ù… Ø§Ù„ÙÙ†ÙŠ": "Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙÙ†ÙŠ",
    "Ø§Ø®Ø° ÙˆÙ‚Øª Ø§ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ù„Ù‘Ø¹Ø¸Ù…": "Ø£Ø®Ø° ÙˆÙ‚Øª Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ù„Ø§Ø²Ù…", "Ø§Ù„Ù„Ø¹Ø¸Ù…": "Ø§Ù„Ù„Ø§Ø²Ù…", "Ù…Ø´ Ø²ÙŠ Ù…Ø§ Ù…ÙƒØªÙˆØ¨": "Ù…Ø´ Ø²ÙŠ Ù…Ø§ Ù‡Ùˆ Ù…ÙƒØªÙˆØ¨",
    "Ø¨Ø£ÙÙŠÙ†": "Ø¨Ù‚Ù‰ ÙÙŠÙ†", "ÙÙŠÙ†": "Ø£ÙŠÙ†", "ÙˆØ§Ù„Ù„Ø³Ù‡": "ÙˆÙ„Ø³Ù‡", "ØªØ¬Ø±Ø¨ØªÙŠ Ù…Ø¹Ø§ÙƒÙ… ÙƒØ§Ù†Øª Ù…ØªØ³": "ØªØ¬Ø±Ø¨ØªÙŠ Ù…Ø¹Ø§ÙƒÙ… ÙƒØ§Ù†Øª Ù…Ù…ØªØ§Ø²Ø©",
    "Ù‡ÙƒØ±Ø±Ù‡Ø§": "Ø³Ø£ÙƒØ±Ø±Ù‡Ø§", "ØªØ§Ù†ÙŠØ§": "Ø«Ø§Ù†ÙŠØ©", "ÙŠÙ†ÙØ¹Ø§Ø¯": "ÙŠÙ†ÙØ¹ Ø£Ø¹Ø¯Ù‘Ù„", "ÙŠÙ†ÙØ¹ Ø§Ø¯": "ÙŠÙ†ÙØ¹ Ø£Ø¹Ø¯Ù‘Ù„", "Ø£Ø¨Ù„": "Ù‚Ø¨Ù„",
    "Ù…Ø§ Ø­Ø¯Ù‡": "Ù…Ø§ Ø­Ø¯Ø§", "Ù„Ø®Ø¨Ø± Ù‡Ùƒ": "Ø§Ù„Ø®Ø¨Ø± Ù‡ÙŠÙƒ", "Ø¨Ø³ÙŠØ±": "Ø¨ØµÙŠØ±", "ÙŠØ¹ØªÙŠÙƒÙ…": "ÙŠØ¹Ø·ÙŠÙƒÙ…", "Ø¹Ø§ÙÙŠ": "Ø§Ù„Ø¹Ø§ÙÙŠØ©",
    "ØªØ£Ø®Ø± ÙˆØ§Ø¬Ø¯": "ØªØ£Ø®Ø± ÙƒØ«ÙŠØ±", "ÙˆØ§Ø¬Ø¯": "ÙƒØ«ÙŠØ±", "Ø¶Ø±ÙˆØ±ÙŠ": "Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ø¬Ù„",
    "Ù„Ùˆ Ø³Ù…Ø­Øª Ù…ØªÙ‰ Ø¨ÙŠÙƒÙˆÙ† Ø§Ù„ØªÙˆØµÙŠÙ„ Ù„Ù„Ø±ÙŠØ§Ø¶ Ø¨Ø§Ù„Ø¹Ø§Ø¯Ø©": "Ù…ØªÙ‰ ÙŠÙˆØµÙ„ Ø§Ù„Ø·Ù„Ø¨ Ù„Ù„Ø±ÙŠØ§Ø¶ Ø¹Ø§Ø¯Ø©ØŸ",
    "ÙŠÙˆÙ…Ø§ÙŠÙ†": "ÙŠÙˆÙ…ÙŠÙ†", "Ù…Ø§ ØªØ¨ÙƒÙˆÙ†": "Ù…Ø§ ØªÙƒÙˆÙ†ÙˆÙ†", "Ø¹Ø¶Ø±ÙˆØ±ÙŠ": "Ø¶Ø±ÙˆØ±ÙŠ"
}

def clean_text(text):
    import re
    text = re.sub(r"[^\u0600-\u06FF\s]", "", text)
    return re.sub(r"\s+", " ", text).strip()

def manual_correction(text):
    for wrong, right in corrections.items():
        text = text.replace(wrong, right)
    return text

def transcribe_audio(path):
    try:
        segments, _ = whisper_model.transcribe(path)
        return " ".join([seg.text for seg in segments])
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ: {str(e)}")
        return ""

uploaded_files = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ©", type=["wav", "mp3", "flac"], accept_multiple_files=True)

if uploaded_files and whisper_model and sentiment_pipeline:
    st.info("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©...")
    results = []
    
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª..."):
        for uploaded_file in uploaded_files:
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                    tmp_file.write(uploaded_file.read())
                    tmp_path = tmp_file.name

                call_id = os.path.splitext(uploaded_file.name)[0]
                raw = transcribe_audio(tmp_path)
                clean = clean_text(raw)
                corrected = manual_correction(clean)

                try:
                    if corrected.strip() == "" or len(corrected.split()) < 3:
                        sentiment = {"label": "neutral", "score": 0.5}
                    else:
                        sentiment = sentiment_pipeline(corrected)[0]
                except Exception as e:
                    sentiment = {"label": "neutral", "score": 0.5}
                    st.warning(f"âš ï¸ ØªØ¹Ø°Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù…Ù„Ø©: {corrected} - {str(e)}")

                label = sentiment["label"]
                score = round(sentiment["score"], 2)
                rank = "High" if label == "negative" and score > 0.8 else "Medium" if label == "negative" else "Low"

                results.append({
                    "call_id": call_id,
                    "text_raw": raw,
                    "text_clean": clean,
                    "text_corrected": corrected,
                    "sentiment_label": label,
                    "sentiment_score": score,
                    "rank": rank
                })
                
                # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                if os.path.exists(tmp_path):
                    os.unlink(tmp_path)
                    
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù {uploaded_file.name}: {str(e)}")

    if not results:
        st.error("âŒ Ù„Ù… ÙŠØªÙ… Ø¥Ù†ØªØ§Ø¬ Ø£ÙŠ Ù†ØªØ§Ø¦Ø¬ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰")
        st.stop()

    df = pd.DataFrame(results)
    
    # Ø§Ù„ØªØ·ÙˆÙŠØ±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: ÙÙ„ØªØ± ÙˆØªÙ„ÙˆÙŠÙ† Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©
    st.subheader("ğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    # ÙÙ„ØªØ± Ø­Ø³Ø¨ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
    sentiment_filter = st.multiselect(
        "ØªØµÙÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±",
        options=["positive", "negative", "neutral"],
        default=["positive", "negative", "neutral"]
    )
    
    if sentiment_filter:
        filtered_df = df[df["sentiment_label"].isin(sentiment_filter)]
    else:
        filtered_df = df.copy()
    
    # ØªÙ„ÙˆÙŠÙ† Ø§Ù„ØµÙÙˆÙ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ø¹ Ø¶Ù…Ø§Ù† Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©
    def color_sentiment(row):
        styles = ["color: black; text-align: right"] * len(row)  # Ù†Øµ Ø£Ø³ÙˆØ¯ ÙˆÙ…Ø­Ø§Ø°Ø§Ø© Ù„Ù„ÙŠÙ…ÙŠÙ†
        
        if row["sentiment_label"] == "negative":
            styles = [f"{s}; background-color: #ffcccc" for s in styles]
        elif row["sentiment_label"] == "positive":
            styles = [f"{s}; background-color: #ccffcc" for s in styles]
        else:
            styles = [f"{s}; background-color: #ffffcc" for s in styles]  # Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£ØµÙØ± Ù„Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ø­Ø§ÙŠØ¯Ø©
        
        return styles
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù…Ø¹ Ø§Ù„ØªÙ„ÙˆÙŠÙ†
    if not filtered_df.empty:
        styled_df = filtered_df[["call_id", "text_corrected", "sentiment_label", "sentiment_score", "rank"]] \
            .style.apply(color_sentiment, axis=1)
        
        st.dataframe(styled_df, use_container_width=True)
    else:
        st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ ØªØ·Ø§Ø¨Ù‚ Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„ØªØµÙÙŠØ©")

    col1, col2 = st.columns(2)
    with col1:
        if not df.empty:
            st.plotly_chart(px.pie(df, names="sentiment_label", title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"), use_container_width=True)
        else:
            st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ")
    with col2:
        if not df.empty:
            st.plotly_chart(px.bar(df, x="rank", color="rank", title="ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª"), use_container_width=True)
        else:
            st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ")

    st.subheader("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    st.download_button("ğŸ“¥ JSON", json.dumps(results, ensure_ascii=False, indent=2), file_name="call_results.json", mime="application/json")
    st.download_button("ğŸ“¥ CSV", df.to_csv(index=False).encode("utf-8-sig"), file_name="call_results.csv", mime="text/csv")

    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    clear_memory()
elif not whisper_model or not sentiment_pipeline:
    st.error("âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­ØŒ ÙŠØ±Ø¬Ù‰ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØµÙØ­Ø© ÙˆØ­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰")
