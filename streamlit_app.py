import streamlit as st
import os
import tempfile
import pandas as pd
import plotly.express as px
import json
from faster_whisper import WhisperModel
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import torch
import gc
import re

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù…", layout="wide")
st.title("ğŸ§ ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©")

# Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø©
def clear_memory():
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper
@st.cache_resource
def load_whisper_model():
    try:
        model = WhisperModel("base", device="cpu", compute_type="float32")
        return model
    except Exception as e:
        st.error(f"âŒ Whisper Model Load Failed: {str(e)}")
        return None

whisper_model = load_whisper_model()

# Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
@st.cache_resource
def load_sentiment_model():
    try:
        model_name = "CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        return pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
    except Exception as e:
        st.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {e}")
        return None

# Ù†Ù…ÙˆØ°Ø¬ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
@st.cache_resource
def load_topic_model():
    try:
        return pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
    except Exception as e:
        st.warning(f"âš ï¸ ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: {e}")
        return None

sentiment_pipeline = load_sentiment_model()
topic_pipeline = load_topic_model()

# ØªØµØ­ÙŠØ­Ø§Øª Ø§Ù„Ù„Ù‡Ø¬Ø§Øª
corrections = {
    "Ø´Ù†Ù„": "Ø´Ù†Ùˆ", "Ø£Ø¨Ø±ÙŠØ¨Ø§": "Ø£Ø¨ØºÙŠ", "Ù…Ø¹ Ø¨ÙˆÙ„": "Ù…Ø¹ Ø¨ÙˆÙ„ÙŠØµØ©", "ØªØ§Ø²ÙŠ": "ØªØ§Ø²Ø©",
    "Ø§Ø¯Ø§Ù… Ø§Ù„ÙÙ†ÙŠ": "Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙÙ†ÙŠ", "Ø§Ù„ÙØªÙˆØ±": "Ø§Ù„ÙØ§ØªÙˆØ±Ø©", "Ø²ÙŠØ§Ø¯": "Ø²ÙŠØ§Ø¯Ø©",
    "Ø§Ù„Ù„ÙŠØ²ÙˆÙ…": "Ø§Ù„Ù„Ø²ÙˆÙ…", "Ø§Ù„Ù…ØµØ§Ø¯Ø©": "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©", "Ø¨Ø¯ÙŠ Ø¨Ø·Ù„": "Ø¨Ø¯ÙŠ Ø£Ø¨Ø¯Ù„",
    "ÙÙŠÙ†": "Ø£ÙŠÙ†", "Ø§Ù„Ø¹Ù„Ø§Ù†": "Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†", "ØªØ£Ø¨Ù„": "ØªÙ‚Ø¨Ù„", "Ø§Ù„Ø¶ÙØ¹": "Ø§Ù„Ø¯ÙØ¹",
    "Ø¨ÙŠÙ‚Ø§Ù„": "Ø¨Ø§ÙŠ Ø¨Ø§Ù„", "Ø§Ù„Ù…ÙˆØ§Ø¶Ù": "Ø§Ù„Ù…ÙˆØ¸Ù", "Ù…Ù‡Ø¯Ø¨": "Ù…Ù‡Ø°Ø¨",
    "Ø·ÙˆØ¨": "Ù…Ø¹Ø·ÙˆØ¨", "Ø¯ÙŠÙ„": "Ø¨Ø¯ÙŠÙ„", "Ù…ÙŠØª": "Ù…Ø§ ÙŠØª", "Ø§Ø¯": "Ø£Ø¹Ø¯Ù‘Ù„"
}

def manual_correction(text):
    for wrong, right in corrections.items():
        text = text.replace(wrong, right)
    return text

def clean_text(text):
    return re.sub(r"[^\u0600-\u06FF\s]", "", text).strip()

def transcribe_audio(path):
    try:
        segments, _ = whisper_model.transcribe(path)
        return " ".join([seg.text for seg in segments])
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª: {e}")
        return ""

# Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…Ù‚ØªØ±Ø­Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
TOPIC_CANDIDATES = [
    "Ø§Ù„Ø¯ÙØ¹", "Ø§Ù„Ø´Ø­Ù†", "Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹", "Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ù„Ø³Ø¹Ø±", "Ø§Ù„ØªÙˆØµÙŠÙ„",
    "Ù…Ø´ÙƒÙ„Ø© ÙÙ†ÙŠØ©", "Ø·Ù„Ø¨ Ù…Ø³Ø§Ø¹Ø¯Ø©", "Ø§Ù„Ø¶Ù…Ø§Ù†", "Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ø§Ù…", "Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡"
]

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
uploaded_files = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ©", type=["wav", "mp3", "flac"], accept_multiple_files=True)

if uploaded_files and whisper_model and sentiment_pipeline:
    st.info("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©...")
    results = []

    with st.spinner("â³ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª..."):
        for uploaded_file in uploaded_files:
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                    tmp_file.write(uploaded_file.read())
                    tmp_path = tmp_file.name

                call_id = os.path.splitext(uploaded_file.name)[0]
                raw = transcribe_audio(tmp_path)
                clean = clean_text(raw)
                corrected = manual_correction(clean)

                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                try:
                    sentiment = sentiment_pipeline(corrected)[0] if len(corrected.split()) >= 3 else {"label": "neutral", "score": 0.5}
                except:
                    sentiment = {"label": "neutral", "score": 0.5}

                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
                try:
                    topic = topic_pipeline(corrected, TOPIC_CANDIDATES)
                    best_topic = topic["labels"][0]
                except:
                    best_topic = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

                rank = "High" if sentiment["label"] == "negative" and sentiment["score"] > 0.8 else \
                       "Medium" if sentiment["label"] == "negative" else "Low"

                results.append({
                    "call_id": call_id,
                    "text_raw": raw,
                    "text_clean": clean,
                    "text_corrected": corrected,
                    "sentiment_label": sentiment["label"],
                    "sentiment_score": round(sentiment["score"], 2),
                    "rank": rank,
                    "topic": best_topic
                })

                os.unlink(tmp_path)

            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù {uploaded_file.name}: {e}")

    if not results:
        st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø¥Ù†ØªØ§Ø¬ Ù†ØªØ§Ø¦Ø¬")
        st.stop()

    df = pd.DataFrame(results)

    # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    st.subheader("ğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    st.dataframe(df[["call_id", "text_corrected", "sentiment_label", "sentiment_score", "rank", "topic"]], use_container_width=True)

    # Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
    col1, col2 = st.columns(2)
    with col1:
        st.plotly_chart(px.pie(df, names="sentiment_label", title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"), use_container_width=True)
    with col2:
        st.plotly_chart(px.bar(df, x="topic", color="rank", title="ØªØµÙ†ÙŠÙ Ø­Ø³Ø¨ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹"), use_container_width=True)

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    st.subheader("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ JSON", json.dumps(results, ensure_ascii=False, indent=2), file_name="call_results.json", mime="application/json")
    st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ CSV", df.to_csv(index=False).encode("utf-8-sig"), file_name="call_results.csv", mime="text/csv")

    clear_memory()

elif not whisper_model:
    st.error("âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª")
elif not sentiment_pipeline:
    st.error("âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±")
