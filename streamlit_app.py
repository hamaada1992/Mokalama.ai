
import streamlit as st
import os
import tempfile
import pandas as pd
import plotly.express as px
import json
import re
from faster_whisper import WhisperModel
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import streamlit as st
import os
import tempfile
import pandas as pd
import plotly.express as px
import json
from faster_whisper import WhisperModel
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import re

st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù…", layout="wide")
st.title("ğŸ§ ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©")

@st.cache_resource
def load_whisper_model():
    return WhisperModel("base", device="cpu", compute_type="float32")

@st.cache_resource
def load_sentiment_model():
    model_name = "CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    return pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

whisper_model = load_whisper_model()
sentiment_pipeline = load_sentiment_model()

corrections = {
    "Ø§Ù„ÙØªÙˆØ±": "Ø§Ù„ÙØ§ØªÙˆØ±Ø©", "Ø²ÙŠØ§Ø¯": "Ø²ÙŠØ§Ø¯Ø©", "Ø§Ù„Ù„ÙŠØ²ÙˆÙ…": "Ø§Ù„Ù„Ø²ÙˆÙ…", "Ø§Ù„Ù…ØµØ§Ø¯Ø©": "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©",
    "Ø¨Ø¯ÙŠ Ø¨Ø·Ù„": "Ø¨Ø¯ÙŠ Ø£Ø¨Ø¯Ù„", "Ù…Ø¹ Ø¨ÙˆÙ„": "Ù…Ø¹ Ø¨ÙˆÙ„ÙŠØµØ©", "ØªØ§Ø²ÙŠ": "ØªØ§Ø²Ø©", "Ø§Ø¯Ø§Ù… Ø§Ù„ÙÙ†ÙŠ": "Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙÙ†ÙŠ",
    "ÙÙŠÙ†": "Ø£ÙŠÙ†", "Ø¨Ø£ÙÙŠÙ†": "Ø¨Ù‚Ù‰ ÙÙŠÙ†", "Ø´Ù†Ù„": "Ø´Ù†Ùˆ", "Ø§Ù„Ù…ÙˆØ§Ø¶Ù": "Ø§Ù„Ù…ÙˆØ¸Ù", "Ù…Ù‡Ø¯Ø¨": "Ù…Ù‡Ø°Ø¨",
    "Ø§Ù„Ø¹Ù„Ø§Ù†": "Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†", "Ø·ÙˆØ¨": "Ù…Ø¹Ø·ÙˆØ¨", "Ø£Ø¨Ø±ÙŠØ¨Ø§": "Ø£Ø¨ØºÙŠ", "Ø¯ÙŠÙ„": "Ø¨Ø¯ÙŠÙ„", "Ø§Ø¯": "Ø£Ø¹Ø¯Ù‘Ù„",
    "Ù…ÙŠØª": "Ù…Ø§ ÙŠØª", "Ù…Ø§ ØªØ¨ÙƒÙˆÙ†": "Ù…Ø§ ØªÙƒÙˆÙ†ÙˆÙ†", "Ø¹Ø¶Ø±ÙˆØ±ÙŠ": "Ø¶Ø±ÙˆØ±ÙŠ", "ÙŠØªØ´Ø­Ù„": "ÙŠØªØ´Ø­Ù†",
    "ØªØºÙ„ÙŠÙ": "Ø§Ù„ØªØºÙ„ÙŠÙ", "Ø§Ù„Ø¬ÙˆØ¯ÙŠ": "Ø§Ù„Ø¬ÙˆØ¯Ø©", "Ø§Ø²Ø¨ÙˆØ¹Ø©": "Ø£Ø³Ø¨ÙˆØ¹", "ØªØ¬Ø±Ø¨ØªÙŠ Ù…Ø¹Ø§ÙƒÙ… ÙƒØ§Ù†Øª Ù…ØªØ³": "ØªØ¬Ø±Ø¨ØªÙŠ Ù…Ø¹Ø§ÙƒÙ… ÙƒØ§Ù†Øª Ù…Ù…ØªØ§Ø²Ø©",
    "Ù‡ÙƒØ±Ø±Ù‡Ø§": "Ø³Ø£ÙƒØ±Ø±Ù‡Ø§", "ØªØ§Ù†ÙŠØ§": "Ø«Ø§Ù†ÙŠØ©", "Ø£Ø¨Ù„": "Ù‚Ø¨Ù„"
}

def manual_correction(text):
    for wrong, right in corrections.items():
        text = text.replace(wrong, right)
    return text

def clean_text(text):
    text = re.sub(r"[^Ø€-Û¿\s]", "", text)
    return re.sub(r"\s+", " ", text).strip()

def transcribe_audio(path):
    segments, _ = whisper_model.transcribe(path)
    return " ".join([seg.text for seg in segments])

uploaded_files = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ©", type=["wav", "mp3", "flac"], accept_multiple_files=True)

if uploaded_files:
    st.info("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„...")
    results = []

    for uploaded_file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_path = tmp_file.name

        call_id = os.path.splitext(uploaded_file.name)[0]
        raw = transcribe_audio(tmp_path)
        clean = clean_text(raw)
        corrected = manual_correction(clean)

        if len(corrected.split()) < 3 or re.search(r"[a-zA-Z]", corrected):
            continue

        try:
            sentiment = sentiment_pipeline(corrected)[0]
        except Exception:
            sentiment = {"label": "neutral", "score": 0.5}

        label = sentiment["label"]
        score = round(sentiment["score"], 2)
        rank = "High" if label == "negative" and score > 0.8 else "Medium" if label == "negative" else "Low"

        results.append({
            "call_id": call_id,
            "text_raw": raw,
            "text_clean": clean,
            "text_corrected": corrected,
            "sentiment_label": label,
            "sentiment_score": score,
            "rank": rank
        })

    if results:
        df = pd.DataFrame(results)
        st.subheader("ğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
        st.dataframe(df[["call_id", "text_corrected", "sentiment_label", "sentiment_score", "rank"]], use_container_width=True)

        col1, col2 = st.columns(2)
        with col1:
            fig1 = px.pie(df, names="sentiment_label", title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±")
            st.plotly_chart(fig1, use_container_width=True)
        with col2:
            fig2 = px.bar(df, x="rank", color="rank", title="ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª")
            st.plotly_chart(fig2, use_container_width=True)

        st.subheader("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
        st.download_button("ğŸ“¥ JSON", json.dumps(results, ensure_ascii=False, indent=2), file_name="call_results.json", mime="application/json")
        st.download_button("ğŸ“¥ CSV", df.to_csv(index=False).encode("utf-8-sig"), file_name="call_results.csv", mime="text/csv")
    else:
        st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„")
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù…", layout="wide")
st.title("ğŸ§ ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ§Ù„Ù…ÙˆØ¶ÙˆØ¹")

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper
@st.cache_resource
def load_whisper_model():
    return WhisperModel("tiny", device="cpu")

whisper_model = load_whisper_model()

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
@st.cache_resource
def load_sentiment_model():
    model_name = "CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    return pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

sentiment_pipeline = load_sentiment_model()

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
@st.cache_resource
def load_topic_model():
    return pipeline(
        "zero-shot-classification",
        model="facebook/bart-large-mnli",
        hypothesis_template="Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø© ØªØªØ¹Ù„Ù‚ Ø¨Ù€ {}.",
        device=-1
    )

topic_pipeline = load_topic_model()

# Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
TOPIC_CANDIDATES = [
    "Ø§Ù„Ø¯ÙØ¹", "Ø§Ù„Ø´Ø­Ù†", "Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹", "Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡",
    "Ù…Ø´ÙƒÙ„Ø© ÙÙ†ÙŠØ©", "Ø·Ù„Ø¨ Ù…Ø³Ø§Ø¹Ø¯Ø©", "Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ø§Ù…",
    "Ø§Ù„Ø¶Ù…Ø§Ù†", "Ø§Ù„ØªÙˆØµÙŠÙ„", "Ø§Ù„Ù…Ù†ØªØ¬", "Ø§Ù„Ø³Ø¹Ø±"
]

# Ø§Ù„ØªØµØ­ÙŠØ­Ø§Øª Ø§Ù„ÙŠØ¯ÙˆÙŠØ© Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø§Ù„Ù„Ù‡Ø¬Ø§Øª
corrections = {
    "Ø§Ù„ÙØªÙˆØ±": "Ø§Ù„ÙØ§ØªÙˆØ±Ø©", "Ø²ÙŠØ§Ø¯": "Ø²ÙŠØ§Ø¯Ø©", "Ø§Ù„Ù„ÙŠØ²ÙˆÙ…": "Ø§Ù„Ù„Ø²ÙˆÙ…",
    "Ø§Ù„Ù…ØµØ§Ø¯Ø©": "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©", "Ø¨Ø¯ÙŠ Ø¨Ø·Ù„": "Ø¨Ø¯ÙŠ Ø£Ø¨Ø¯Ù„", "Ù…Ø¹ Ø¨ÙˆÙ„": "Ù…Ø¹ Ø¨ÙˆÙ„ÙŠØµØ©",
    "ØªØ§Ø²ÙŠ": "ØªØ§Ø²Ø©", "Ø§Ø¯Ø§Ù… Ø§Ù„ÙÙ†ÙŠ": "Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙÙ†ÙŠ", "Ø£Ø¨Ø±ÙŠ": "Ø£Ø¨ØºÙŠ", "Ø¨Ø¯Ø¨Øª": "Ø¨Ø¯ÙŠ Ø¨Ø¯ÙŠÙ„",
    "Ø§Ø¯Ø§Ù… Ø§Ù„ÙÙ†ÙŠÙƒØ§": "Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙÙ†ÙŠ ÙƒØ§Ù†", "Ø§ØªØ§Ø®ÙŠØ±": "ØªØ£Ø®ÙŠØ±", "Ø§Ù„Ù…Ø³Ø§Ø¯Ø©": "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©",
    "Ù…Ø¹Ø¨ÙˆÙ„": "Ù…Ø¹Ù‚ÙˆÙ„", "Ø§Ø²Ø¨ÙˆØ¹Ø©": "Ø£Ø³Ø¨ÙˆØ¹", "Ø§Ù„Ø¬ÙˆØ¯ÙŠ": "Ø§Ù„Ø¬ÙˆØ¯Ø©", "Ø§ØªØºÙ„ÙŠÙ": "Ø§Ù„ØªØºÙ„ÙŠÙ",
    "Ø§Ù…Ø§ ÙƒØªÙŠØ±": "Ø£Ø¹Ø¬Ø¨Ù†ÙŠ ÙƒØ«ÙŠØ±Ù‹Ø§", "Ø§Ù„Ø¹Ù„Ø§Ù„": "Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†", "Ø§Ù„Ù…ÙˆØ¶Ù": "Ø§Ù„Ù…ÙˆØ¸Ù",
    "Ø£ÙÙŠÙ†": "ÙÙŠÙ†", "Ø£Ø¨Ù„": "Ù‚Ø¨Ù„", "ÙŠØªØ´Ø­Ù„": "ÙŠØªØ´Ø­Ù†", "Ø¨Ø§Ù„Ø¯ÙŠ": "Ø¨Ø¯ÙŠ",
    "Ø´Ù†Ù„": "Ø´Ù†Ùˆ", "Ù…Ù‡Ø¯Ø¨": "Ù…Ù‡Ø°Ø¨", "Ø·ÙˆØ¨": "Ù…Ø¹Ø·ÙˆØ¨", "Ø¯ÙŠÙ„": "Ø¨Ø¯ÙŠÙ„",
    "Ø§Ø¯": "Ø£Ø¹Ø¯Ù‘Ù„", "Ù…ÙŠØª": "Ù…Ø§ ÙŠØª", "Ù…Ø§ ØªØ¨ÙƒÙˆÙ†": "Ù…Ø§ ØªÙƒÙˆÙ†ÙˆÙ†",
    "Ø¹Ø¶Ø±ÙˆØ±ÙŠ": "Ø¶Ø±ÙˆØ±ÙŠ", "ØªØ¬Ø±Ø¨ØªÙŠ Ù…Ø¹Ø§ÙƒÙ… ÙƒØ§Ù†Øª Ù…ØªØ³": "ØªØ¬Ø±Ø¨ØªÙŠ Ù…Ø¹Ø§ÙƒÙ… ÙƒØ§Ù†Øª Ù…Ù…ØªØ§Ø²Ø©",
    "Ù‡ÙƒØ±Ø±Ù‡Ø§": "Ø³Ø£ÙƒØ±Ø±Ù‡Ø§", "ØªØ§Ù†ÙŠØ§": "Ø«Ø§Ù†ÙŠØ©"
}

def clean_text(text):
    text = re.sub(r"[^Ø€-Û¿\s]", "", text)
    return re.sub(r"\s+", " ", text).strip()

def manual_correction(text):
    for wrong, right in corrections.items():
        text = text.replace(wrong, right)
    return text

def transcribe_audio(path):
    segments, _ = whisper_model.transcribe(path)
    return " ".join([seg.text for seg in segments])

uploaded_files = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ©", type=["wav", "mp3", "flac"], accept_multiple_files=True)

if uploaded_files:
    st.info("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„...")
    results = []

    for uploaded_file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_path = tmp_file.name

        call_id = os.path.splitext(uploaded_file.name)[0]
        raw = transcribe_audio(tmp_path)
        clean = clean_text(raw)
        corrected = manual_correction(clean)

        try:
            sentiment = sentiment_pipeline(corrected)[0] if len(corrected.split()) >= 3 else {"label": "neutral", "score": 0.5}
        except:
            sentiment = {"label": "neutral", "score": 0.5}

        try:
            topic_result = topic_pipeline(corrected, TOPIC_CANDIDATES)
            best_topic = topic_result["labels"][0]
            best_topic_score = round(topic_result["scores"][0], 2)
        except:
            best_topic = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
            best_topic_score = 0.0

        label = sentiment["label"]
        score = round(sentiment["score"], 2)
        rank = "High" if label == "negative" and score > 0.8 else "Medium" if label == "negative" else "Low"

        results.append({
            "call_id": call_id,
            "text_raw": raw,
            "text_clean": clean,
            "text_corrected": corrected,
            "sentiment_label": label,
            "sentiment_score": score,
            "rank": rank,
            "topic": best_topic,
            "topic_score": best_topic_score
        })

    df = pd.DataFrame(results)
    st.subheader("ğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    st.dataframe(df[["call_id", "text_corrected", "sentiment_label", "sentiment_score", "rank", "topic", "topic_score"]], use_container_width=True)

    col1, col2 = st.columns(2)
    with col1:
        st.plotly_chart(px.pie(df, names="sentiment_label", title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"), use_container_width=True)
    with col2:
        st.plotly_chart(px.histogram(df, x="topic", y="topic_score", title="Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª"), use_container_width=True)

    st.subheader("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    st.download_button("ğŸ“¥ JSON", json.dumps(results, ensure_ascii=False, indent=2), file_name="call_results.json", mime="application/json")
    st.download_button("ğŸ“¥ CSV", df.to_csv(index=False).encode("utf-8-sig"), file_name="call_results.csv", mime="text/csv")
