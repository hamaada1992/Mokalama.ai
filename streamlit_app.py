import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["STREAMLIT_SERVER_FILE_WATCHER_TYPE"] = "poll"

import streamlit as st
import tempfile
import pandas as pd
import plotly.express as px
import json
from faster_whisper import WhisperModel
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import time
import re
import concurrent.futures

# ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø¸Ù‡Ø± Ø§Ù„Ø¹Ø§Ù…
st.set_page_config(
    page_title="ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ",
    layout="wide",
    page_icon="ğŸ“",
    initial_sidebar_state="expanded"
)

# ØªØ®ØµÙŠØµ Ø§Ù„Ø£Ù„ÙˆØ§Ù†
st.markdown("""
<style>
    :root {
        --primary: #3498db;
        --secondary: #2ecc71;
        --danger: #e74c3c;
        --warning: #f39c12;
        --dark: #2c3e50;
    }
    
    .st-emotion-cache-1y4p8pa {
        background-color: #f8f9fa;
    }
    
    /* Ø¥ØµÙ„Ø§Ø­ Ø´Ø§Ù…Ù„ Ù„Ù„ÙˆÙ† Ø§Ù„Ø®Ø· ÙÙŠ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ */
    .stDataFrame * {
        color: black !important;
    }
    
    .stDataFrame th, .stDataFrame td {
        color: black !important;
        background-color: transparent !important;
    }
    
    .stDataFrame table {
        color: black !important;
        font-family: Arial, sans-serif !important;
        font-size: 14px !important;
    }
    
    .stDataFrame th {
        font-weight: bold !important;
        background-color: #f0f0f0 !important;
    }
    
    .positive-row {
        background-color: #d4f8e8 !important;
        color: black !important;
    }
    
    .neutral-row {
        background-color: #fff9db !important;
        color: black !important;
    }
    
    .negative-row {
        background-color: #ffdbdb !important;
        color: black !important;
    }
    
    .critical-call {
        border: 2px solid var(--danger);
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        background-color: #fff8f8;
    }
    
    .header {
        color: var(--dark);
        border-bottom: 2px solid var(--primary);
        padding-bottom: 10px;
        margin-bottom: 20px;
    }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ“ ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±")

# ========== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ==========
st.sidebar.header("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")

# Ø¬Ù…ÙŠØ¹ Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙ‚Ø·
MODEL_SIZES = ["tiny", "base", "small", "medium", "large"]

# ÙˆØµÙ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
MODEL_DESCRIPTIONS = {
    "tiny": "Ø§Ù„Ø£Ø³Ø±Ø¹ - Ø¯Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø© (40-50%)",
    "base": "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø³Ø±Ø¹Ø© - Ø¯Ù‚Ø© Ù…Ø¹Ù‚ÙˆÙ„Ø© (60-70%)",
    "small": "Ø¬ÙŠØ¯ - ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„Ø³Ø±Ø¹Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© (70-80%)",
    "medium": "Ù…ØªÙ‚Ø¯Ù… - Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© (80-90%)",
    "large": "Ø§Ù„Ø£ÙØ¶Ù„ - Ø£Ø¹Ù„Ù‰ Ø¯Ù‚Ø© (90%+)"
}

# Ø§Ø®ØªÙŠØ§Ø± Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model_size = st.sidebar.selectbox(
    "Ø­Ø¬Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµÙˆØª",
    options=MODEL_SIZES,
    index=1,  # ØªØ­Ø¯ÙŠØ¯ "base" ÙƒØ¥ÙØªØ±Ø§Ø¶ÙŠ
    format_func=lambda x: f"{x} - {MODEL_DESCRIPTIONS.get(x, '')}",
    help="Ø§Ø®ØªØ± Ù†Ù…ÙˆØ°Ø¬Ø§Ù‹ Ù…Ù†Ø§Ø³Ø¨Ø§Ù‹. Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£ÙƒØ¨Ø± Ø­Ø¬Ù…Ø§Ù‹ Ø£ÙƒØ«Ø± Ø¯Ù‚Ø© ÙˆÙ„ÙƒÙ†Ù‡Ø§ Ø£Ø¨Ø·Ø£"
)

# ========== ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ==========
@st.cache_resource(show_spinner=False)
def load_whisper_model(size):
    st.info(f"â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµÙˆØª ({size})...")
    try:
        return WhisperModel(size, device="cpu", compute_type="int8")
    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµÙˆØª: {str(e)}")
        st.stop()

whisper_model = load_whisper_model(model_size)

@st.cache_resource(show_spinner=False)
def load_sentiment_model():
    model_name = "CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment"
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        return pipeline(
            "sentiment-analysis", 
            model=model, 
            tokenizer=tokenizer,
            truncation=True,
            max_length=128
        )
    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {str(e)}")
        st.stop()

sentiment_pipeline = load_sentiment_model()

# ========== ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ ==========
corrections = {
    "Ø§Ù„ÙØªÙˆØ±": "Ø§Ù„ÙØ§ØªÙˆØ±Ø©",
    "Ø²ÙŠØ§Ø¯": "Ø²ÙŠØ§Ø¯Ø©",
    "Ø§Ù„Ù„ÙŠØ²ÙˆÙ…": "Ø§Ù„Ù„Ù‘Ø²ÙˆÙ…",
    "Ø§Ù„Ù…ØµØ§Ø¯Ø©": "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©",
    "Ø¨Ø¯ÙŠ Ø¨Ø·Ù„": "Ø¨Ø¯ÙŠ Ø£Ø¨Ø¯Ù‘Ù„",
    "Ù…Ø¹ Ø¨ÙˆÙ„": "Ù…Ø¹ Ø¨ÙˆÙ„ÙŠØµØ©",
    "ØªØ§Ø²ÙŠ": "ØªØ§Ø²Ø©",
    "Ø§Ø¯Ø§Ù… Ø§Ù„ÙÙ†ÙŠ": "Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙÙ†ÙŠ",
    "Ø¨Ø§Ù„Ø¯ÙŠ": "Ø¨Ø¯ÙŠ",
    "Ø¥Ø¯Ø§Ù…": "Ø£Ø¯Ø§Ø¡",
    "Ø§Ù„Ø¬ÙˆØ¯ÙŠ": "Ø§Ù„Ø¬ÙˆØ¯Ø©",
    "Ø§Ù„ØªÙˆÙ‚Ø¹Ø§ØªÙŠ": "ØªÙˆÙ‚Ù‘Ø¹Ø§ØªÙŠ",
    "Ù…Ø¹ Ø·ÙˆØ¨": "Ù…Ø¹Ø·ÙˆØ¨",
    "Ø£Ø¨Ø±ÙŠØ¨Ø§ Ø¯ÙŠÙ„": "Ø£Ø¨ØºÙ‰ Ø¨Ø¯ÙŠÙ„",
    "Ø´Ù†Ù„": "Ø´Ù†Ùˆ",
    "Ø´Ù†": "Ø´Ù†Ùˆ",
    "Ø§Ù„Ø¹Ù„Ø§Ù†": "Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†",
    "Ø§Ù„Ù…ÙˆØ§Ø¶Ù": "Ø§Ù„Ù…ÙˆØ¸Ù‘Ù",
    "Ù…Ù‡Ø¯Ø¨": "Ù…Ù‡Ø°Ù‘Ø¨",
    "Ø§Ù„Ø¶ÙØ¹": "Ø§Ù„Ø¯ÙØ¹",
    "Ø¨ÙŠÙ‚Ø§Ù„": "Ø¨Ø§ÙŠØ¨Ø§Ù„",
    "Ø§Ù„Ù„Ø¹Ø¸Ù…": "Ø§Ù„Ù„Ø§Ø²Ù…",
    "ÙŠÙ†ÙØ¹Ø¯": "ÙŠÙ†ÙØ¹ Ø£Ø¹Ø¯Ù‘Ù„",
    "Ø£Ø¨Ù„ Ù…ÙŠØª Ø´Ù‡Ù„": "Ù‚Ø¨Ù„ Ù…Ø§ ÙŠØªØ´Ø­Ù†",
    "Ø£Ø¨Ù„ Ù…ÙŠØª Ø´Ù‡Ø±": "Ù‚Ø¨Ù„ Ù…Ø§ ÙŠØªØ´Ø­Ù†",
    "Ù„Ø®Ø¨Ø± Ù‡Ùƒ Ù…Ø§ Ø¨Ø³ÙŠØ±": "Ø§Ù„Ø®Ø¨Ø± Ù‡ÙŠÙƒ Ù…Ø§ Ø¨ØµÙŠØ±",
    "ÙŠØ¹ØªÙŠÙƒÙ…": "ÙŠØ¹Ø·ÙŠÙƒÙ…",
    "Ø¹Ù† Ø¬Ø¯ Ø§Ù„ØªØ¹Ø§Ù…Ù„": "Ø¹Ù†Ø¬Ø¯ Ø§Ù„ØªØ¹Ø§Ù…Ù„",
    "ÙˆØ´Ø­Ù† ÙˆØµÙ„Øª": "ÙˆØ§Ù„Ø´Ø­Ù†Ø© ÙˆØµÙ„Øª",
    "Ù…Ø§ ØªØ§Ø¨ÙƒÙˆÙ†": "Ù…ØªÙ‰ Ø¨ÙŠÙƒÙˆÙ†",
    "Ù…Ø§ ØªØ¨ÙƒÙˆÙ†": "Ù…ØªÙ‰ Ø¨ÙŠÙƒÙˆÙ†",
    "ØªØ¨ÙƒÙˆÙ†": "Ø¨ÙŠÙƒÙˆÙ†",
    "Ø¹Ø¶Ø±ÙˆØ±ÙŠ": "Ø¶Ø±ÙˆØ±ÙŠ",
    "Ø¨Ø¯ÙŠ Ø£Ù„ØºÙŠ Ø·Ù„Ø¨ Ø±Ø£Ù… ÙˆØ§Ø­Ø¯ Ù„Ø§ØªÙŠ Ø®Ù…Ø³ Ø³Ø¨Ø¹Ø© ØªØ³Ø¹Ø©": "Ø¨Ø¯ÙŠ Ø£Ù„ØºÙŠ Ø·Ù„Ø¨ Ø±Ù‚Ù… Ù¡Ù£Ù¥Ù§Ù©",
    "Ø§Ù„Ù…Ù†ØªÙƒ": "Ø§Ù„Ù…Ù†ØªØ¬",
    "Ø§Ù„ØªØ­ÙØ©": "Ø±Ø§Ø¦Ø¹",
    "Ù…Ø£Ø¨ÙˆÙ„": "Ù…Ù‚Ø¨ÙˆÙ„",
    "Ù…ÙˆØ§Ø¹Ø¯": "Ù…ÙˆØ¹Ø¯",
    "ØªØ£Ø®Ø± ÙˆØ§Ø¬Ø¯": "ØªØ£Ø®Ù‘Ø± ÙƒØ«ÙŠØ±",
    "Ù‡Ø§ ÙƒØ±Ø±Ù‡Ø§": "Ù‡Ø£ÙƒØ±Ù‘Ø±Ù‡Ø§",
    "Ø¨Ø¯ÙŠØ± Ø¬Ø¹Ù„ Ù…Ù† ØªØ¬": "Ø¨Ø¯ÙŠ Ø£Ø±Ø¬Ù‘Ø¹ Ø§Ù„Ù…Ù†ØªØ¬",
    "ØºÙŠØ· Ù„Ø¨ Ø±Ø£Ù…": "Ø£Ù„ØºÙŠ Ø·Ù„Ø¨ Ø±Ù‚Ù…",
    "Ø£ØµÙˆÙ‰": "Ø£Ø³ÙˆØ¡",
    "Ø£Ø®Ø° Ù…ØªØ¹Ù…Ù„Ø§Ø¡": "Ø®Ø¯Ù…Ø© Ø¹Ù…Ù„Ø§Ø¡",
    "Ø§Ù„Ø²Ø¨Ø§Ø¡": "Ø§Ù„Ø²Ø¨Ø§Ø¦Ù†",
    "Ø®Ø¯Ù…Øª":"Ø®Ø¯Ù…Ø©",
    "Ù…Ø±Ø­Ø¶Ø©":"Ù…Ø±Ø­Ø¨Ø§"
}

# ========== Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ (Ù…ÙˆØ³Ø¹) ==========
TOPIC_KEYWORDS = {
    "ÙÙˆØ§ØªÙŠØ±": ["ÙØ§ØªÙˆØ±Ø©", "Ø¯ÙØ¹", "Ø¨Ø§ÙŠØ¨Ø§Ù„", "Ø§Ù„Ø¯ÙØ¹", "Ø§Ù„ÙØ§ØªÙˆØ±Ø©", "Ù…Ø¨Ù„Øº", "Ø±Ø³ÙˆÙ…"],
    "ØªÙˆØµÙŠÙ„": ["ØªÙˆØµÙŠÙ„", "Ø´Ø­Ù†Ø©", "ÙˆØµÙ„Øª", "ØªÙˆØµÙŠÙ„", "Ø§Ù„ØªÙˆØµÙŠÙ„", "Ù…ÙˆØ¹Ø¯ ØªÙˆØµÙŠÙ„", "ØªØ§Ø±ÙŠØ® ØªÙˆØµÙŠÙ„", "ØªØ³Ù„ÙŠÙ…", "Ø§Ù„Ø´Ø­Ù†"],
    "Ø§Ø³ØªÙØ³Ø§Ø±": ["Ø§Ø³ØªÙØ³Ø§Ø±", "Ø³Ø¤Ø§Ù„", "Ø§Ø³ØªØ¹Ù„Ø§Ù…", "Ø§Ø³ØªÙØ³Ø§Ø±", "Ø§Ø³ØªØ¹Ù„Ø§Ù…"],
    "Ø´ÙƒÙˆÙ‰": ["Ø´ÙƒÙˆÙ‰", "Ù…Ø´ÙƒÙ„Ø©", "Ø§Ø¹ØªØ±Ø§Ø¶", "Ø®Ø·Ø£", "ØºÙ„Ø·", "Ù…Ø³ØªØ§Ø¡", "ØºÙŠØ± Ø±Ø§Ø¶ÙŠ"],
    "Ø®Ø¯Ù…Ø© ÙÙ†ÙŠØ©": ["ÙÙ†ÙŠ", "ØªÙ‚Ù†ÙŠ", "ØµÙŠØ§Ù†Ø©", "Ø¥ØµÙ„Ø§Ø­", "Ø¹Ø·Ù„", "Ø£Ø¹Ø·Ø§Ù„"],
    "Ø¨Ø·Ø§Ù‚Ø©": ["Ø¨Ø·Ø§Ù‚Ø©", "ÙƒØ§Ø±Øª", "Ø§Ø¦ØªÙ…Ø§Ù†", "Ù…Ø¯Ù‰", "Ø¨Ø·Ø§Ù‚Ø© Ø§Ø¦ØªÙ…Ø§Ù†"],
    "ØªØ£Ø®ÙŠØ±": ["ØªØ£Ø®ÙŠØ±", "ØªØ£Ø®Ø±Øª", "Ù…ØªØ£Ø®Ø±Ø©", "ØªØ£Ø®Ø±", "Ø£Ø¨Ø·Ø£", "ØªØ£Ø¬ÙŠÙ„"],
    "Ø¥Ù„ØºØ§Ø¡ Ø·Ù„Ø¨": ["Ø¥Ù„ØºØ§Ø¡", "Ø§Ù„ØºÙŠ", "Ø£Ù„ØºÙŠ", "ØªØ±Ø§Ø¬Ø¹", "Ø§Ù„ØºØ§Ø¡", "Ø¥Ù„ØºØ§Ø¡ Ø·Ù„Ø¨", "Ø£Ù„ØºÙŠØª"],
    "Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ù…Ù†ØªØ¬": ["Ø§Ø³ØªØ¨Ø¯Ø§Ù„", "Ø¨Ø¯ÙŠÙ„", "Ø£Ø¨Ø¯Ù„", "ØªØºÙŠÙŠØ±", "Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡", "Ø¨Ø¯ÙŠ Ø£Ø¨Ø¯Ù„"],
    "Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ù…Ù†ØªØ¬": ["Ø§Ø³ØªØ±Ø¬Ø§Ø¹", "Ø£Ø±Ø¬Ø¹", "Ø¥Ø±Ø¬Ø§Ø¹", "Ø£Ø³ØªØ±Ø¯", "Ø±Ø¯ Ø§Ù„Ù…Ù†ØªØ¬"],
    "Ø®ØµÙˆÙ…Ø§Øª ÙˆØ¹Ø±ÙˆØ¶": ["Ø¹Ø±Ø¶", "Ø®ØµÙ…", "ØªØ®ÙÙŠØ¶", "Ø¹Ø±ÙˆØ¶", "ØªÙ†Ø²ÙŠÙ„Ø§Øª", "Ø³Ø¹Ø± Ù…Ø®ÙØ¶"],
    "Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ù†ØªØ¬": ["Ø¬ÙˆØ¯Ø©", "Ù†ÙˆØ¹ÙŠØ©", "Ø±Ø¯ÙŠØ¦Ø©", "Ø±Ø¯ÙŠØ¡", "Ù…Ù…ØªØ§Ø²Ø©", "Ø³ÙŠØ¦Ø©"],
    "Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡": ["Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡", "Ø®Ø¯Ù…Ø© Ø§Ù„Ø²Ø¨Ø§Ø¦Ù†", "Ø¯Ø¹Ù… Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡", "Ù…ÙˆØ¸Ù Ø®Ø¯Ù…Ø©"],
    "ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ù„ÙˆÙ…Ø§Øª": ["ØªØ­Ø¯ÙŠØ«", "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª", "Ø¹Ù†ÙˆØ§Ù†", "Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„", "Ø¨ÙŠØ§Ù†Ø§Øª", "ØªØ¹Ø¯ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª"],
    "Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª": ["Ù…Ù†ØªØ¬", "Ø³Ù„Ø¹Ø©", "Ø¨Ø¶Ø§Ø¹Ø©", "ØµÙ†Ù", "Ø§Ù„Ù…Ø´ØªØ±ÙŠØ§Øª", "Ø§Ù„Ø·Ù„Ø¨"],
    "ØªØªØ¨Ø¹ Ø§Ù„Ø·Ù„Ø¨Ø§Øª": ["ØªØªØ¨Ø¹", "Ø£ÙŠÙ† Ø·Ù„Ø¨ÙŠ", "Ù…ÙƒØ§Ù† Ø§Ù„Ø´Ø­Ù†Ø©", "Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø´Ø­Ù†Ø©", "ØªØªØ¨Ø¹ Ø´Ø­Ù†Ø©"],
    "Ø§Ù„Ø¶Ù…Ø§Ù†": ["Ø¶Ù…Ø§Ù†", "ÙƒÙØ§Ù„Ø©", "ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø¶Ù…Ø§Ù†", "ÙØªØ±Ø© Ø§Ù„Ø¶Ù…Ø§Ù†"]
}

def detect_topic(text):
    if not text:
        return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
    
    text = text.lower()
    topic_counts = {topic: 0 for topic in TOPIC_KEYWORDS}
    
    for topic, keywords in TOPIC_KEYWORDS.items():
        for keyword in keywords:
            if keyword in text:
                topic_counts[topic] += 1
                
    if max(topic_counts.values()) == 0:
        return "Ø£Ø®Ø±Ù‰"
    
    return max(topic_counts, key=topic_counts.get)

# ========== ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© ==========
def clean_text(text):
    if not text:
        return ""
    text = re.sub(r"[^\u0600-\u06FF\s]", "", text)
    return re.sub(r"\s+", " ", text).strip()

def manual_correction(text):
    if not text:
        return ""
    for wrong, right in corrections.items():
        text = text.replace(wrong, right)
    return text

def transcribe_audio(path):
    try:
        segments, _ = whisper_model.transcribe(
            path, 
            beam_size=1,
            vad_filter=True,
            language="ar",
            without_timestamps=True
        )
        return " ".join([seg.text for seg in segments])
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ: {str(e)}")
        return ""

# ========== Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ÙƒØ§Ù„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© ==========
def process_call(uploaded_file):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_path = tmp_file.name
        
        call_id = os.path.splitext(uploaded_file.name)[0]
        
        raw = transcribe_audio(tmp_path)
        
        if not raw.strip():
            return {
                "call_id": call_id,
                "error": "ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ",
                "text_raw": "",
                "text_clean": "",
                "text_corrected": "",
                "sentiment_label": "error",
                "sentiment_score": 0.0,
                "rank": "Error",
                "topic": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
            }
        
        clean = clean_text(raw)
        corrected = manual_correction(clean)
        topic = detect_topic(corrected)
        
        if not corrected.strip():
            final_label = "neutral"
            final_score = 0.0
        else:
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ ØµØºÙŠØ±Ø© Ù„ØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ Ø·ÙˆÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚
            max_chunk_size = 128
            chunks = [corrected[i:i+max_chunk_size] for i in range(0, len(corrected), max_chunk_size)]
            sentiments = sentiment_pipeline(chunks)
            
            # Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            scores = []
            labels = []
            for s in sentiments:
                labels.append(s['label'])
                scores.append(s['score'])
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªÙˆØ³Ø·
            label_counts = {"positive": 0, "negative": 0, "neutral": 0}
            for l in labels:
                label_counts[l] += 1
            
            final_label = max(label_counts, key=label_counts.get)
            final_score = round(sum(scores) / len(scores), 2)
        
        if final_label == "negative":
            if final_score > 0.85:
                rank = "Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹"
            elif final_score > 0.7:
                rank = "Ø¹Ø§Ù„ÙŠØ©"
            else:
                rank = "Ù…ØªÙˆØ³Ø·Ø©"
        elif final_label == "positive":
            rank = "Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©"
        else:
            rank = "Ù…Ø­Ø§ÙŠØ¯Ø©"

        return {
            "call_id": call_id,
            "text_raw": raw,
            "text_clean": clean,
            "text_corrected": corrected,
            "sentiment_label": final_label,
            "sentiment_score": final_score,
            "rank": rank,
            "topic": topic
        }
        
    except Exception as e:
        return {
            "call_id": uploaded_file.name,
            "error": str(e),
            "text_raw": "",
            "text_clean": "",
            "text_corrected": "",
            "sentiment_label": "error",
            "sentiment_score": 0.0,
            "rank": "Error",
            "topic": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
        }
    finally:
        if 'tmp_path' in locals():
            try:
                os.unlink(tmp_path)
            except:
                pass

# ========== ÙˆØ§Ø¬Ù‡Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª ==========
uploaded_files = st.file_uploader(
    "ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ© (WAV, MP3, FLAC)", 
    type=["wav", "mp3", "flac"], 
    accept_multiple_files=True
)

# ========== Ø§Ù„ÙÙ„Ø§ØªØ± ==========
if uploaded_files:
    st.sidebar.header("ğŸ” ØªØµÙÙŠØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    # ÙÙ„ØªØ±Ø© Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
    sentiment_options = ["Ø³Ù„Ø¨ÙŠ", "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ", "Ù…Ø­Ø§ÙŠØ¯"]
    selected_sentiments = st.sidebar.multiselect(
        "Ø§Ù„Ù…Ø´Ø§Ø¹Ø±",
        options=sentiment_options,
        default=sentiment_options
    )
    
    # ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©
    rank_options = ["Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹", "Ø¹Ø§Ù„ÙŠØ©", "Ù…ØªÙˆØ³Ø·Ø©", "Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©", "Ù…Ø­Ø§ÙŠØ¯Ø©"]
    selected_ranks = st.sidebar.multiselect(
        "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©",
        options=rank_options,
        default=rank_options
    )
    
    # ÙÙ„ØªØ±Ø© Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹
    topic_options = sorted(set(TOPIC_KEYWORDS.keys()) | {"Ø£Ø®Ø±Ù‰", "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"})
    selected_topics = st.sidebar.multiselect(
        "Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹",
        options=topic_options,
        default=topic_options
    )

# ========== Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª ==========
if uploaded_files:
    st.info(f"ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ {len(uploaded_files)} Ù…ÙƒØ§Ù„Ù…Ø©...")
    start_time = time.time()
    results = []
    progress_bar = st.progress(0)
    status_text = st.empty()

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ© Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø³Ø±Ø¹Ø©
    max_workers = min(4, len(uploaded_files))  # Ù„Ø§ ØªØ²ÙŠØ¯ Ø¹Ù† 4 Ø¹Ù…Ø§Ù„
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_file = {executor.submit(process_call, file): file for file in uploaded_files}
        
        for i, future in enumerate(concurrent.futures.as_completed(future_to_file)):
            file = future_to_file[future]
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø© {file.name}: {str(e)}")
            
            # ØªØ­Ø¯ÙŠØ« Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
            progress_percent = int((i + 1) / len(uploaded_files) * 100)
            progress_bar.progress(progress_percent)
            status_text.text(f"ğŸ“ ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© {i+1}/{len(uploaded_files)} Ù…ÙƒØ§Ù„Ù…Ø©")

    progress_bar.empty()
    status_text.empty()
    
    end_time = time.time()
    total_time = end_time - start_time
    avg_time = total_time / len(uploaded_files) if uploaded_files else 0
    st.success(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„! Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {total_time:.1f} Ø«Ø§Ù†ÙŠØ© ({avg_time:.1f} Ø«Ø§Ù†ÙŠØ©/Ù…ÙƒØ§Ù„Ù…Ø©)")

    if results:
        df = pd.DataFrame(results)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„Ø§ØªØ±
        sentiment_map = {"Ø³Ù„Ø¨ÙŠ": "negative", "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ": "positive", "Ù…Ø­Ø§ÙŠØ¯": "neutral"}
        selected_labels = [sentiment_map[s] for s in selected_sentiments]
        
        filtered_df = df[
            df['sentiment_label'].isin(selected_labels) &
            df['rank'].isin(selected_ranks) &
            df['topic'].isin(selected_topics)
        ]
        
        # ========== Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø­Ø±Ø¬Ø© ==========
        critical_calls = df[(df['sentiment_label'] == 'negative') & (df['rank'].isin(['Ø¹Ø§Ù„ÙŠØ©', 'Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹']))]
        
        if not critical_calls.empty:
            st.warning(f"ğŸš¨ ØªÙ†Ø¨ÙŠÙ‡: ÙŠÙˆØ¬Ø¯ {len(critical_calls)} Ù…ÙƒØ§Ù„Ù…Ø© Ø³Ù„Ø¨ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ© ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…ØªØ§Ø¨Ø¹Ø© Ø¹Ø§Ø¬Ù„Ø©!")
            
            for _, row in critical_calls.iterrows():
                with st.expander(f"Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø© Ø§Ù„Ø­Ø±Ø¬Ø©: {row['call_id']}", expanded=False):
                    st.markdown(f"**Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹:** {row['topic']}")
                    st.markdown(f"**Ø§Ù„Ù…Ø³ØªÙˆÙ‰:** {row['rank']}")
                    st.markdown(f"**Ù†Øµ Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø©:**")
                    st.write(row['text_corrected'])
        
        # ========== Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ==========
        if filtered_df.empty:
            st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©")
        else:
            tab1, tab2, tab3 = st.tabs(["Ø§Ù„Ù†ØªØ§Ø¦Ø¬", "Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©", "ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"])
            
            with tab1:
                st.subheader("ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
                
                # ØªÙ„ÙˆÙŠÙ† Ø§Ù„ØµÙÙˆÙ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                def color_row(row):
                    styles = [''] * len(row)
                    if row['sentiment_label'] == 'positive':
                        styles = ['background-color: #d4f8e8;'] * len(row)
                    elif row['sentiment_label'] == 'neutral':
                        styles = ['background-color: #fff9db;'] * len(row)
                    elif row['sentiment_label'] == 'negative':
                        styles = ['background-color: #ffdbdb;'] * len(row)
                    return styles
                
                # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ„ÙˆÙŠÙ† Ø¹Ù„Ù‰ DataFrame
                display_df = filtered_df[["call_id", "topic", "sentiment_label", "sentiment_score", "rank"]].copy()
                styled_df = display_df.style.apply(color_row, axis=1)
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù…Ø¹ ØªØ®ØµÙŠØµØ§Øª Ø¥Ø¶Ø§ÙÙŠØ©
                st.dataframe(
                    styled_df,
                    use_container_width=True,
                    height=400
                )
                
                st.subheader("ğŸ” Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„Ø©")
                for idx, row in filtered_df.iterrows():
                    with st.expander(f"Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø©: {row['call_id']} (Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: {row['topic']})", expanded=False):
                        if row['sentiment_label'] == 'negative' and row['rank'] in ['Ø¹Ø§Ù„ÙŠØ©', 'Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹']:
                            st.warning("âš ï¸ Ù…ÙƒØ§Ù„Ù…Ø© Ø³Ù„Ø¨ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ© - ØªØ­ØªØ§Ø¬ Ù…ØªØ§Ø¨Ø¹Ø© Ø¹Ø§Ø¬Ù„Ø©!")
                        
                        st.caption("Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:")
                        st.write(row['text_raw'])
                        st.caption("Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ­Ø­:")
                        st.write(row['text_corrected'])
                        st.caption(f"ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {row['sentiment_label']} (Ø«Ù‚Ø©: {row['sentiment_score']:.2f})")
                        st.caption(f"Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: {row['rank']}")
                        st.caption(f"Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: {row['topic']}")
            
            with tab2:
                st.subheader("ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ØµØ±ÙŠ")
                
                col1, col2 = st.columns(2)
                with col1:
                    # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                    sentiment_counts = filtered_df['sentiment_label'].value_counts().reset_index()
                    sentiment_counts.columns = ['sentiment', 'count']
                    fig1 = px.pie(
                        sentiment_counts, 
                        names='sentiment', 
                        values='count',
                        title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±",
                        color='sentiment',
                        color_discrete_map={'positive': '#2ecc71', 'negative': '#e74c3c', 'neutral': '#f39c12'}
                    )
                    st.plotly_chart(fig1, use_container_width=True)
                    
                    # Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                    if not filtered_df.empty:
                        fig3 = px.bar(
                            filtered_df, 
                            x="topic", 
                            color="sentiment_label",
                            title="Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±",
                            color_discrete_map={'positive': '#2ecc71', 'negative': '#e74c3c', 'neutral': '#f39c12'}
                        )
                        st.plotly_chart(fig3, use_container_width=True)
                    
                with col2:
                    # Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø£Ù‡Ù…ÙŠØ©
                    if not filtered_df.empty:
                        fig2 = px.bar(
                            filtered_df, 
                            x="rank", 
                            color="sentiment_label",
                            title="Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø£Ù‡Ù…ÙŠØ©",
                            category_orders={"rank": ["Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹", "Ø¹Ø§Ù„ÙŠØ©", "Ù…ØªÙˆØ³Ø·Ø©", "Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©", "Ù…Ø­Ø§ÙŠØ¯Ø©"]},
                            color_discrete_map={'positive': '#2ecc71', 'negative': '#e74c3c', 'neutral': '#f39c12'}
                        )
                        st.plotly_chart(fig2, use_container_width=True)
                    
                    # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ ÙˆØ§Ù„Ù…Ø´Ø§Ø¹Ø±
                    if not filtered_df.empty:
                        fig4 = px.treemap(
                            filtered_df, 
                            path=['topic', 'sentiment_label'], 
                            values='sentiment_score',
                            title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ ÙˆØ§Ù„Ù…Ø´Ø§Ø¹Ø±",
                            color='sentiment_label',
                            color_discrete_map={'positive': '#2ecc71', 'negative': '#e74c3c', 'neutral': '#f39c12'}
                        )
                        st.plotly_chart(fig4, use_container_width=True)
            
            with tab3:
                st.subheader("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.download_button(
                        "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ JSON", 
                        json.dumps(results, ensure_ascii=False, indent=2), 
                        file_name="call_results.json", 
                        mime="application/json"
                    )
                with col2:
                    st.download_button(
                        "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ CSV", 
                        filtered_df.to_csv(index=False).encode("utf-8-sig"), 
                        file_name="call_results.csv", 
                        mime="text/csv"
                    )
                
                st.caption("Ù…Ø¹Ø§ÙŠÙ†Ø© JSON:")
                st.json(results[0] if len(results) > 0 else {})
