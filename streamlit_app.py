import streamlit as st
import os
import tempfile
import pandas as pd
import plotly.express as px
import json
from faster_whisper import WhisperModel
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification

st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù…", layout="wide")
st.title("ğŸ§ ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±")

@st.cache_resource
def load_whisper_model():
    return WhisperModel("base", device="cpu")

whisper_model = load_whisper_model()

@st.cache_resource
def load_sentiment_model():
    model_name = "CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    return pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

sentiment_pipeline = load_sentiment_model()

corrections = {
    # ğŸ§© ØªØµØ­ÙŠØ­Ø§Øª Ù„ØºÙˆÙŠØ© Ø¹Ø§Ù…Ø©
    "Ø§Ù„ÙØªÙˆØ±": "Ø§Ù„ÙØ§ØªÙˆØ±Ø©", "Ø²ÙŠØ§Ø¯": "Ø²ÙŠØ§Ø¯Ø©", "Ø§Ù„Ù„ÙŠØ²ÙˆÙ…": "Ø§Ù„Ù„Ø²ÙˆÙ…",
    "Ø§Ù„Ù…ØµØ§Ø¯Ø©": "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©", "Ø§Ù„Ø¬ÙˆØ¯ÙŠ": "Ø§Ù„Ø¬ÙˆØ¯Ø©", "Ø§ØªØºÙ„ÙŠÙ": "Ø§Ù„ØªØºÙ„ÙŠÙ",
    "Ø§Ù„Ø¹Ù„Ø§Ù„": "Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†", "Ø§Ø¯": "Ø£Ø¹Ø¯Ù‘Ù„", "Ù…ÙŠØª": "Ù…Ø§ ÙŠØª", "ÙÙŠÙ†": "Ø£ÙŠÙ†",

    # ğŸ‡ªğŸ‡¬ Ù…ØµØ±ÙŠ
    "Ø¨Ø£ÙÙŠÙ†": "Ø¨Ù‚Ù‰ ÙÙŠÙ†", "Ù…Ø´ Ø²ÙŠ Ù…Ø§ Ù…ÙƒØªÙˆØ¨": "Ù…Ø´ Ø²ÙŠ Ù…Ø§ Ù‡Ùˆ Ù…ÙƒØªÙˆØ¨", "Ù‡ÙƒØ±Ø±Ù‡Ø§": "Ø³Ø£ÙƒØ±Ø±Ù‡Ø§",
    "ØªØ§Ù†ÙŠ": "Ø«Ø§Ù†ÙŠØ©", "Ø¹Ø§ÙŠØ²": "Ø£Ø±ÙŠØ¯", "Ù…Ø´ ÙØ§Ù‡Ù…": "Ù„Ø§ Ø£ÙÙ‡Ù…", "Ù…ØªØ§Ø®Ø±": "Ù…ØªØ£Ø®Ø±", "ØªÙ…Ø§Ù…": "Ø¬ÙŠØ¯",
    "ØªÙ…Ø§Ù… ÙƒØ¯Ù‡": "Ø¬ÙŠØ¯ Ø¬Ø¯Ù‹Ø§", "Ø­Ø§Ø³Ø³": "Ø£Ø´Ø¹Ø±", "Ø¹Ø§Ù…Ù„ Ø§ÙŠÙ‡": "ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ", "Ø¹Ù†Ø¯ÙŠ Ù…Ø´ÙƒÙ„Ø©": "Ø£ÙˆØ§Ø¬Ù‡ Ù…Ø´ÙƒÙ„Ø©",

    # ğŸ‡¸ğŸ‡¦ Ø³Ø¹ÙˆØ¯ÙŠ / Ø®Ù„ÙŠØ¬ÙŠ
    "Ø£Ø¨Ø±ÙŠ": "Ø£Ø¨ØºÙŠ", "Ø£Ø¨Ø±ÙŠØ¨Ø§": "Ø£Ø¨ØºÙŠ", "Ø¨Ø¯ÙŠ Ø¨Ø·Ù„": "Ø¨Ø¯ÙŠ Ø£Ø¨Ø¯Ù„", "Ù…Ø¹ Ø¨ÙˆÙ„": "Ù…Ø¹ Ø¨ÙˆÙ„ÙŠØµØ©",
    "Ø´Ù†Ù„": "Ø´Ù†Ùˆ", "Ø´Ù†Ù‡": "Ø´Ù†Ùˆ", "ØªØ§Ø²ÙŠ": "ØªØ§Ø²Ø©", "ØªØ£Ø®Ø± ÙˆØ§Ø¬Ø¯": "ØªØ£Ø®Ø± ÙƒØ«ÙŠØ±", "ÙˆØ§Ø¬Ø¯": "ÙƒØ«ÙŠØ±",
    "Ø¨Ø§Ù„Ø¯ÙŠ": "Ø¨Ø¯ÙŠ", "Ø¹Ù†Ø¯ÙŠ Ø§Ø³ØªÙØ³Ø§Ø±": "Ø£Ø±ÙŠØ¯ Ø£Ù† Ø£Ø³Ø£Ù„", "Ø®Ù„Ù†Ø§": "Ø¯Ø¹Ù†Ø§", "ÙˆØ´": "Ù…Ø§",
    "Ù…Ø§ Ø¹Ù„ÙŠÙ‡": "Ù„Ø§ Ø¨Ø£Ø³", "ÙŠØ´ØªØºÙ„ØŸ": "Ù‡Ù„ ÙŠØ¹Ù…Ù„ØŸ",

    # ğŸ‡µğŸ‡¸ğŸ‡±ğŸ‡§ğŸ‡¯ğŸ‡´ğŸ‡¸ğŸ‡¾ Ø´Ø§Ù…ÙŠ
    "Ù…Ø§ Ø­Ø¯Ù‡": "Ù…Ø§ Ø­Ø¯Ø§", "Ø¨Ø³ÙŠØ±": "Ø¨ØµÙŠØ±", "Ù„Ø®Ø¨Ø± Ù‡Ùƒ": "Ø§Ù„Ø®Ø¨Ø± Ù‡ÙŠÙƒ", "ÙŠØ¹ØªÙŠÙƒÙ…": "ÙŠØ¹Ø·ÙŠÙƒÙ…",
    "Ø¹Ø§ÙÙŠ": "Ø§Ù„Ø¹Ø§ÙÙŠØ©", "Ù…Ù†ÙŠØ­": "Ø¬ÙŠØ¯", "ÙƒØªÙŠØ±": "ÙƒØ«ÙŠØ±", "Ù…Ø§Ø´ÙŠ Ø§Ù„Ø­Ø§Ù„": "ØªÙ…Ø§Ù…",
    "Ø´Ùˆ": "Ù…Ø§", "Ù‚Ø¯ÙŠØ´": "ÙƒÙ…", "Ù‚Ø¯ÙŠØ´ Ø§Ù„Ø³Ø¹Ø±": "ÙƒÙ… Ø§Ù„Ø³Ø¹Ø±",

    # ğŸ‡²ğŸ‡¦ğŸ‡©ğŸ‡¿ğŸ‡¹ğŸ‡³ Ù…ØºØ§Ø±Ø¨ÙŠ
    "Ø¨Ø±Ø´Ø§": "ÙƒØ«ÙŠØ±", "Ù…Ø§ ÙÙ‡Ù…ØªØ´": "Ù„Ù… Ø£ÙÙ‡Ù…", "Ø®Ø§Ø·Ø±": "Ù„Ø£Ù†", "ÙˆØ§Ø´": "Ù‡Ù„", "Ø´Ù†Ùˆ": "Ù…Ø§",
    "Ø²Ø¹Ù…Ø§": "Ù‡Ù„ ÙŠÙ…ÙƒÙ†", "Ø­Ø§Ø¬Ø©": "Ø´ÙŠØ¡", "Ø¹Ù„Ø§Ø´": "Ù„Ù…Ø§Ø°Ø§", "ØªÙ‚Ø¯Ø§": "ØªØµÙ„Ø­",
    "Ù‡Ø§Ø¯ÙŠ": "Ù‡Ø°Ù‡", "Ù‡Ø¯ÙŠÙƒ": "ØªÙ„Ùƒ", "Ù…Ø§Ø¹Ø¬Ø¨Ù†ÙŠØ´": "Ù„Ù… ÙŠØ¹Ø¬Ø¨Ù†ÙŠ",

    # ğŸ‡¸ğŸ‡© Ø³ÙˆØ¯Ø§Ù†ÙŠ
    "Ø´Ù†Ùˆ": "Ù…Ø§", "ÙƒØªÙŠØ±": "ÙƒØ«ÙŠØ±", "ØªÙ…Ø§Ù…": "Ø¬ÙŠØ¯", "ÙƒÙˆÙŠØ³": "Ø¬ÙŠØ¯", "Ø³Ø§ÙƒØª": "ÙÙ‚Ø·",
    "Ø®Ù„Ø§Øµ": "Ø§Ù†ØªÙ‡Ù‰", "Ù„Ø³Ù‡": "Ù…Ø§ Ø²Ø§Ù„", "ØºØ§ÙŠØªÙˆ": "Ø¹Ù„Ù‰ ÙƒÙ„ Ø­Ø§Ù„",

    # ğŸ‡¾ğŸ‡ª ÙŠÙ…Ù†ÙŠ
    "Ù…Ø¹ÙŠ": "Ø¹Ù†Ø¯ÙŠ", "Ù„ÙŠØ´": "Ù„Ù…Ø§Ø°Ø§", "Ø°ÙŠ": "Ø§Ù„Ø°ÙŠ", "Ù‡Ø§Ù†Ø§": "Ø£Ù†Ø§ Ù‡Ù†Ø§",
    "Ù‚Ø¹": "ÙƒÙ†", "Ø§Ù†Ù‚Ø¯": "Ø£Ø¯ÙØ¹", "Ø­ÙŠØ¯": "Ø§Ø°Ù‡Ø¨", "Ø´Ø§Øµ": "Ø³ÙŠØ§Ø±Ø©",

    # âœ¨ ØªØµØ­ÙŠØ­Ø§Øª ÙÙ†ÙŠØ© ÙˆØ¹Ù…Ù„ÙŠØ©
    "ÙŠØªØ´Ø­Ù„": "ÙŠØªØ´Ø­Ù†", "Ù…Ø´Ø¨ÙˆÙƒ": "Ù…ØªØµÙ„", "ÙØ§ØµÙ„": "ØºÙŠØ± Ù…ØªØµÙ„", "Ø´Ø¨ÙƒØ© ØªØ¹Ø¨Ø§Ù†Ø©": "Ø§Ù„Ø§ØªØµØ§Ù„ Ø¶Ø¹ÙŠÙ",
    "Ù…Ø§ ÙŠØ±Ø¯": "Ù„Ø§ ÙŠØ¬ÙŠØ¨", "Ø§ØªØµØ§Ù„ Ø³ÙŠØ¡": "Ø§Ù„Ø§ØªØµØ§Ù„ Ø¶Ø¹ÙŠÙ", "Ø§Ù„ØµÙˆØª ÙŠÙ‚Ø·Ø¹": "Ø§Ù„ØµÙˆØª ØºÙŠØ± ÙˆØ§Ø¶Ø­",

    # ØªØµØ­ÙŠØ­Ø§Øª ØªØ±ÙƒÙŠØ¨ÙŠØ© ÙˆÙ…Ø±Ø§Ø¯ÙØ§Øª
    "Ø§Ø¯Ø§Ù… Ø§Ù„ÙÙ†ÙŠ": "Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙÙ†ÙŠ", "Ø§Ø¯Ø§Ù… Ø§Ù„ÙÙ†ÙŠÙƒØ§": "Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙÙ†ÙŠ ÙƒØ§Ù†", "Ø¨Ø¯Ø¨Øª": "Ø¨Ø¯ÙŠ Ø¨Ø¯ÙŠÙ„",
    "Ø§Ø²Ø¨ÙˆØ¹Ø©": "Ø£Ø³Ø¨ÙˆØ¹", "Ø£Ù…Ø§ ÙƒØªÙŠØ±": "Ø£Ø¹Ø¬Ø¨Ù†ÙŠ ÙƒØ«ÙŠØ±Ù‹Ø§", "Ø§Ù„Ù…ÙˆØ¶Ù": "Ø§Ù„Ù…ÙˆØ¸Ù"
}


def clean_text(text):
    import re
    text = re.sub(r"[^\u0600-\u06FF\s]", "", text)
    return re.sub(r"\s+", " ", text).strip()

def manual_correction(text):
    for wrong, right in corrections.items():
        text = text.replace(wrong, right)
    return text

def transcribe_audio(path):
    segments, _ = whisper_model.transcribe(path, language="ar")
    return " ".join([seg.text for seg in segments])

uploaded_files = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ©", type=["wav", "mp3", "flac"], accept_multiple_files=True)

if uploaded_files:
    st.info("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„...")
    results = []

    for uploaded_file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_path = tmp_file.name

        call_id = os.path.splitext(uploaded_file.name)[0]
        raw = transcribe_audio(tmp_path)
        clean = clean_text(raw)
        corrected = manual_correction(clean)
        sentiment = sentiment_pipeline(corrected)[0]
        label = sentiment["label"]
        score = round(sentiment["score"], 2)
        rank = "High" if label == "negative" and score > 0.8 else "Medium" if label == "negative" else "Low"

        results.append({
            "call_id": call_id,
            "text_raw": raw,
            "text_clean": clean,
            "text_corrected": corrected,
            "sentiment_label": label,
            "sentiment_score": score,
            "rank": rank
        })

    df = pd.DataFrame(results)
    st.subheader("ğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    st.dataframe(df[["call_id", "text_corrected", "sentiment_label", "sentiment_score", "rank"]], use_container_width=True)

    col1, col2 = st.columns(2)
    with col1:
        fig1 = px.pie(df, names="sentiment_label", title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±")
        st.plotly_chart(fig1, use_container_width=True)
    with col2:
        fig2 = px.bar(df, x="rank", color="rank", title="ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª")
        st.plotly_chart(fig2, use_container_width=True)

    st.subheader("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    st.download_button("ğŸ“¥ JSON", json.dumps(results, ensure_ascii=False, indent=2), file_name="call_results.json", mime="application/json")
    st.download_button("ğŸ“¥ CSV", df.to_csv(index=False).encode("utf-8-sig"), file_name="call_results.csv", mime="text/csv")
